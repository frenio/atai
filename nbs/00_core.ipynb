{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> The core package contains all functions, variables, and classes needed to train a deep neural network model and inspect its activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "import sys, gc, traceback\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from copy import copy\n",
    "from functools import partial\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from torcheval.metrics import BinaryAccuracy, Mean, BinaryAUROC\n",
    "from torcheval.metrics.functional import binary_auroc, binary_accuracy\n",
    "from torchmetrics.classification import BinaryMatthewsCorrCoef\n",
    "\n",
    "import fastcore.all as fc\n",
    "from fastprogress import progress_bar, master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%matplotlib inline\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Protein Solubility Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example dataset is from the [DeepSol](https://doi.org/10.1093/bioinformatics/bty166) paper by Khurana *et al.* and was obtained at [https://zenodo.org/records/1162886](https://zenodo.org/records/1162886)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERVAAKVVLSKMTLGDLRNNPVVPYETDEVTRIIQDQVNDRIHDSIKNWTVEELREWILDHKTTDADIKRVARGLTSEIIAAVTKLMSNLDLIYGAKKIRVIAHANTTIGLPGTFSARLQPNHPTDDPDGILASLMEGLTYGIGDAVIGLNPVDDSTDSVVRLLNKFEEFRSKWDVPTQTCVLAHVKTQMEAMRRGAPTGLVFQSIAGSEKGNTAFGFDGATIEEARQLALQSGAATGPNVMYFETGQGSELSSDAHFGVDQVTMEARCYGFAKKFDPFLVNTVVGFIGPEYLYDSKQVIRAGLEDHFMGKLTGISMGCDVCYTNHMKADQNDVENLSVLLTAAGCNFIMGIPHGDDVMLNYQTTGYHETATLRELFGLKPIKEFDQWMEKMGFSENGKLTSRAGDASIFLK',\n",
       "  'MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEYSKTGDAWPCVLLRKKSFEDLHKLYYICLKEKNKLLGEQYFHLQNSTKMLQHGRLKKVKLTMKRILTVLSRRAIHDQCLRAKDMLKKQEEREFYEIQKFKLNEQLLCLKHKMNILKKYNSFSLEQISLTFSIKKIENKIQQIDIILNPLRKETMYLLIPHFKYQRKYSDLPGFISWKKQNIIALRNNMSKLHRLY'],\n",
       " [1, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sqs = open('sol_data/train_src', 'r').read().splitlines()\n",
    "train_tgs = list(map(int, open('sol_data/train_tgt', 'r').read().splitlines()))\n",
    "train_sqs[:2], train_tgs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SRLYRHNLMEDVFNMENESFMQETRLMENEYSVNLPTRFYYKKRWNNGFVNIVNIFRACMVIGTPGSGKSYAIVNSYIRQLIAKGFAIYIYDYKFDDLSTIAYNSLLKNMDKYEVKPRFYVINFDDPRRSHRCNPINPEFMTDISDAYEASYTIMLNLNRTWIEKQGDFFVESPIILLAAIIWYLKIYKNGIYCTFPHAVELLNKPYSDLFTILTSYPELENYLSPFMDAWKGNAQDQLQGQIASAKIPLTRMISPQLYWVMTGNDFSLDINNPKEPKLLCVGNNPDRQNIYSAALGLYNSRIVKLINKKKQLKCAVIIDELPTIYFRGLDNLIATARSNKVGVLLGFQDFSQLTRDYGEKESKVIQNTVGNIFSGQVVGETAKTLSERFGKVLQQRQSVSINRQDVSTSINTQLDSLIPASKIANLSQGTFVGAVADNFDERIEQKIFHAEIVVDHTKISAEEKAYQKIPVINDFKDRNGNDIMMQQIQRNYDQIKADAQAIINEEMRRIKNDPELRKRLGLEDEKGKDPDKS',\n",
       "  'ATTYNAVVSKSSSDGKTFKTIADAIASAPAGSTPFVILIKNGVYNERLTITRNNLHLKGESRNGAVIAAATAAGTLKSDGSKWGTAGSSTITISAKDFSAQSLTIRNDFDFPANQAKSDSDSSKIKDTQAVALYVTKSGDRAYFKDVSLVGYQATLYVSGGRSFFSDCRISGTVDFIFGDGTALFNNCDLVSRYRADVKSGNVSGYLTAPSTNINQKYGLVITNSRVIRESDSVPAKSYGLGRPWHPTTTFSDGRYADPNAIGQTVFLNTSMDNHIYGWDKMSGKDKNGNTIWFNPEDSRFFEYKSYGAGATVSKDRRQLTDAQAAEYTQSKVLGDWTPTLP'],\n",
       " [0, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sqs = open('sol_data/val_src', 'r').read().splitlines()\n",
    "valid_tgs = list(map(int, open('sol_data/val_tgt', 'r').read().splitlines()))\n",
    "valid_sqs[:2], valid_tgs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MLSVRIAAAVARALPRRAGLVSKNALGSSFVGTRNLHASNTRLQKTGTAEMSSILEERILGADTSVDLEETGRVLSIGDGIARVHGLRNVQAEEMVEFSSGLKGMSLNLEPDNVGVVVFGNDKLIKEGDIVKRTGAIVDVPVGDELLGRVVDALGNAIDGKGPVGSKIRRRVGLKAPGIIPRISVREPMQTGIKAVDSLVPIGRGQRELIIGDRQTGKTSIAIDTIINQKRFNDGTDEKKKLYCIYVAIGQKRSTVAQLVKRLTDADAMKYTIVVSATASDAAPLQYLAPYSGCSMGEYFRDNGKHALIIYDDLSKQAVAYRQMSLLLRRPPGREAYPGDVFYLHSRLLERAAKMNDSFGGGSLTALPVIETQAGDVSAYIPTNVISITDGQIFLETELFYKGIRPAINVGLSVSRVGSAAQTRAMKQVAGTMKLELAQYREVAAFAQFGSDLDAATQQLLSRGVRLTELLKQGQYSPMAIEEQVAVIYAGVRGYLDKLEPSKITKFESAFLSHVVSQHQSLLGNIRSDGKISEQSDAKLKEIVTNFLAGFEP',\n",
       "  'MDHMISENGETSAEGSICGYDSLHQLLSANLKPELYQEVNRLLLGRNCGRSLEQIVLPESAKALSSKHDFDLQAASFSADKEQMRNPRVVRVGLIQNSIALPTTAPFSDQTRGIFDKLKPIIDAAGVAGVNILCLQEAWTMPFAFCTRERRWCEFAEPVDGESTKFLQELAKKYNMVIVSPILERDIDHGEVLWNTAVIIGNNGNIIGKHRKNHIPRVGDFNESTYYMEGDTGHPVFETVFGKIAVNICYGRHHPLNWLAFGLNGAEIVFNPSATVGELSEPMWPIEARNAAIANSYFVGSINRVGTEVFPNPFTSGDGKPQHNDFGHFYGSSHFSAPDASCTPSLSRYKDGLLISDMDLNLCRQYKDKWGFRMTARYEVYADLLAKYIKPDFKPQVVSDPLLHKNST'],\n",
       " [1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sqs = open('sol_data/test_src', 'r').read().splitlines()\n",
    "test_tgs = list(map(int, open('sol_data/test_tgt', 'r').read().splitlines()))\n",
    "test_sqs[:2], test_tgs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62478, 62478, 6942, 6942, 1999, 1999)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sqs), len(train_tgs), len(valid_sqs), len(valid_tgs), len(test_sqs), len(test_tgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sorted list of amino acid sequences `aas` including an empty string for padding and determine the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['',\n",
       "  'A',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y'],\n",
       " 21)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aas = sorted(list(set(\"\".join(train_sqs))) + [\"\"])\n",
    "vocab_size = len(aas)\n",
    "aas, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries that translate between string and integer representations of amino acids and define the corresponding `encode` and `decode` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 19, 2, 2, 2, 6, 6, 6, 7, 7]\n",
      "AYWCCCGGGHH\n"
     ]
    }
   ],
   "source": [
    "str2int = {aa:i for i, aa in enumerate(aas)}\n",
    "int2str = {i:aa for i, aa in enumerate(aas)}\n",
    "encode = lambda s: [str2int[aa] for aa in s]\n",
    "decode = lambda l: ''.join([int2str[i] for i in l])\n",
    "\n",
    "print(encode(\"AYWCCCGGGHH\"))\n",
    "print(decode(encode(\"AYWCCCGGGHH\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out what the lengths of amino acid sequences in the dataset are and inspect the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lens = list(map(len, train_sqs))\n",
    "max(train_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSGEVRLRQLEQFILDGPAQTNGQCFSVETLLDILICLYDECNNSPLRREKNILEYLEWAKPFTSKVKQMRLHREDFEILKVIGRGAFGEVAVVKLKNADKVFAMKILNKWEMLKRAETACFREERDVLVNGDNKWITTLHYAFQDDNNLYLVMDYYVGGDLLTLLSKFEDRLPEDMARFYLAEMVIAIDSVHQLHYVHRDIKPDNILMDMNGHIRLADFGSCLKLMEDGTVQSSVAVGTPDYISPEILQAMEDGKGRYGPECDWWSLGVCMYEMLYGETPFYAESLVETYGKIMNHKERFQFPAQVTDVSENAKDLIRRLICSREHRLGQNGIEDFKKHPFFSGIDWDNIRNCEAPYIPEVSSPTDTSNFDVDDDCLKNSETMPPPTHTAFSGHHLPFVGFTYTSSCVLSDRSCLRVTAGPTSLDLDVNVQRTLDNNLATEAYERRIKRLEQEKLELSRKLQESTQTVQALQYSTVDGPLTASKDLEIKNLKEEIEKLRKQVTESSHLEQQLEEANAVRQELDDAFRQIKAYEKQIKTLQQEREDLNKELVQASERLKNQSKELKDAHCQRKLAMQEFMEINERLTELHTQKQKLARHVRDKEEEVDLVMQKVESLRQELRRTERAKKELEVHTEALAAEASKDRKLREQSEHYSKQLENELEGLKQKQISYSPGVCSIEHQQEITKLKTDLEKKSIFYEEELSKREGIHANEIKNLKKELHDSEGQQLALNKEIMILKDKLEKTRRESQSEREEFESEFKQQYEREKVLLTEENKKLTSELDKLTTLYENLSIHNQQLEEEVKDLADKKESVAHWEAQITEIIQWVSDEKDARGYLQALASKMTEELEALRNSSLGTRATDMPWKMRRFAKLDMSARLELQSALDAEIRAKQAIQEELNKVKASNIITECKLKDSEKKNLELLSEIEQLIKDTEELRSEKGIEHQDSQHSFLAFLNTPTDALDQFERKTHQFFVKSFTTPTKCHQCTSLMVGLIRQGCSCEVCGFSCHITCVNKAPTTCPVPPEQTKGPLGIDPQKGIGTAYEGHVRIPKPAGVKKGWQRALAIVCDFKLFLYDIAEGKASQPSVVISQVIDMRDEEFSVSSVLASDVIHASRKDIPCIFRVTASQLSASNNKCSILMLADTENEKNKWVGVLSELHKILKKNKFRDRSVYVPKEAYDSTLPLIKTTQAAAIIDHERIALGNEEGLFVVHVTKDEIIRVGDNKKIHQIELIPNDQLVAVISGRNRHVRLFPMSALDGRETDFYKLSETKGCQTVTSGKVRHGALTCLCVAMKRQVLCYELFQSKTRHRKFKEIQVPYNVQWMAIFSEQLCVGFQSGFLRYPLNGEGNPYSMLHSNDHTLSFIAHQPMDAICAVEISSKEYLLCFNSIGIYTDCQGRRSRQQELMWPANPSSCCYNAPYLSVYSENAVDIFDVNSMEWIQTLPLKKVRPLNNEGSLNLLGLETIRLIYFKNKMAEGDELVVPETSDNSRKQMVRNINNKRRYSFRVPEEERMQQRREMLRDPEMRNKLISNPTNFNHIAHMGPGDGIQILKDLPMNPRPQESRTVFSGSVSIPSITKSRPEPGRSMSASSGLSARSSAQNGSALKREFSGGSYSAKRQPMPSPSEGSLSSGGMDQGSDAPARDFDGEDSDSPRHSTASNSSNLSSPPSPVSPRKTKSLSLESTDRGSWDP'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest = train_sqs[np.argmax(train_lens)]\n",
    "longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many sequences in the training set are longer than 1200 amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_sqs = []\n",
    "for sq in train_sqs:\n",
    "    if len(sq) > 1200:\n",
    "        long_sqs.append(sq)\n",
    "len(long_sqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that drops all sequences above a chosen threshold and also returns a list of indices of the sequences that meet the threshold that can be used to obtain the correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_long_sqs(sqs, threshold=1200):\n",
    "    new_sqs = []\n",
    "    idx = []\n",
    "    for i, sq in enumerate(sqs):\n",
    "        if len(sq) <= threshold:\n",
    "            new_sqs.append(sq)\n",
    "            idx.append(i)\n",
    "    return new_sqs, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all sequences above your threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsqs, trnidx = drop_long_sqs(train_sqs, threshold=200)\n",
    "vldsqs, vldidx = drop_long_sqs(valid_sqs, threshold=200)\n",
    "tstsqs, tstidx = drop_long_sqs(test_sqs, threshold=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18066, 1971, 699)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trnidx), len(vldidx), len(tstidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnls = map(len, trnsqs)\n",
    "vldls = map(len, vldsqs)\n",
    "tstls = map(len, tstsqs)\n",
    "max(trnls), max(vldls), max(tstls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for zero padding all sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(sq, length=1200):\n",
    "    new_sq = sq.copy()\n",
    "    if len(new_sq) < length:\n",
    "        new_sq.extend([0] * (length-len(new_sq)))\n",
    "    return new_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now encode and zero pad all sequences and make sure that it worked out correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the first two sequences before zero padding: 116, 135\n",
      "Length of the first two sequences after zero padding:  200, 200\n"
     ]
    }
   ],
   "source": [
    "trn = list(map(encode, trnsqs))\n",
    "vld = list(map(encode, vldsqs))\n",
    "tst = list(map(encode, tstsqs))\n",
    "print(f\"Length of the first two sequences before zero padding: {len(trn[0])}, {len(trn[1])}\")\n",
    "trn = list(map(partial(zero_pad, length=200), trn))\n",
    "vld = list(map(partial(zero_pad, length=200), vld))\n",
    "tst = list(map(partial(zero_pad, length=200), tst))\n",
    "print(f\"Length of the first two sequences after zero padding:  {len(trn[0])}, {len(trn[1])}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data to `torch.tensor`s unsing `dtype=torch.int64` and check for correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18066, 200]),\n",
       " tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n",
       "          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n",
       "          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n",
       "          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trntns = torch.tensor(trn, dtype=torch.int64)\n",
    "vldtns = torch.tensor(vld, dtype=torch.int64)\n",
    "tsttns = torch.tensor(tst, dtype=torch.int64)\n",
    "trntns.shape, trntns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18066, 200]), torch.Size([1971, 200]), torch.Size([699, 200]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trntns.shape, vldtns.shape, tsttns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the correct labels using the lists of indices obtained from the `drop_long_sqs` function and convert the lists of labels to tensors in `torch.float32` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18066]), torch.Size([1971]), torch.Size([699]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnlbs = torch.tensor(train_tgs, dtype=torch.float32)[trnidx]\n",
    "vldlbs = torch.tensor(valid_tgs, dtype=torch.float32)[vldidx]\n",
    "tstlbs = torch.tensor(test_tgs, dtype=torch.float32)[tstidx]\n",
    "trnlbs.shape, vldlbs.shape, tstlbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4722129967895494, 0.4657534246575342, 0.5665236051502146)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnlbs.sum().item()/trnlbs.shape[0], vldlbs.sum().item()/vldlbs.shape[0], tstlbs.sum().item()/tstlbs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above ratios tell us that there are slightly less than half soluble proteins in the training an validation data, and slightly more than half in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Dataset` class and combine tokens and labels into datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset():\n",
    "    \"Combines features and lables in a dataset.\"\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n",
       "          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n",
       "          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n",
       "          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnds = Dataset(trntns, trnlbs)\n",
    "vldds = Dataset(vldtns, vldlbs)\n",
    "tstds = Dataset(tsttns, tstlbs)\n",
    "trnds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `DataLoaders` class and a function that creates your DataLoaders given a train dataset, a valid dataset, and a batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoaders():\n",
    "    \"Combines training and validation data in a DataLoaders object that can be passed to a learner.\"\n",
    "    def __init__(self, *dls): self.train, self.valid = dls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dls(train_ds, valid_ds, bs=32):\n",
    "    \"Turn training and validation set into a DataLoaders object.\"\n",
    "    train_dl = DataLoader(train_ds, bs, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, bs, shuffle=False)\n",
    "    return DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the DataLoaders object and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11, 16, 10,  9, 17,  7, 17, 10, 13, 10, 10, 10, 16,  2, 17, 10,  5, 10,  8,  6,  1,  2, 17, 16, 11, 13, 13,  4,  8, 15, 12,  5, 16,\n",
       "           1, 18,  3,  8, 13, 20, 14, 13, 18, 16, 14, 12,  1,  4, 17, 20,  9,  3,  1, 13, 18, 15, 19,  6,  6, 17, 18,  8,  4, 18,  4, 12,  4,\n",
       "          17,  3,  5, 16, 10, 11, 14, 18, 10,  5,  7, 13, 10,  3, 15, 16,  6, 20, 13,  4, 17, 15,  9, 13,  6,  4,  6, 15,  5,  1, 18,  4,  8,\n",
       "          12,  4,  5, 10,  3, 13,  1,  8, 20, 17,  9,  6, 18,  4, 18, 17, 18,  8,  6, 17, 18,  9,  6, 12,  8,  4, 15, 17,  8,  6, 12,  9, 17,\n",
       "           8,  7,  8, 13, 10,  8, 17,  1,  9, 17,  8,  7, 10, 19, 13, 14,  1, 20, 15,  4,  3, 12, 10, 20, 15, 20,  6, 13, 20, 13,  6, 20, 20,\n",
       "           6, 20,  6, 20, 13,  5,  5, 20, 12,  6, 20, 20, 15, 13, 20, 15,  5, 19, 19,  4,  6,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0],\n",
       "         [11, 17, 20, 17, 17,  1,  9,  1,  1,  4,  9,  8,  6,  8, 16,  1,  7, 17, 10, 15,  5, 20,  3,  9,  4,  6, 10, 10, 13, 12,  8,  6, 15,\n",
       "           3,  4, 20,  6, 12, 15,  2,  5, 17,  3, 12,  3, 10, 14, 19, 10,  6, 10, 10, 14,  2, 10,  9, 12, 17,  6, 11, 16, 10,  9,  3,  8,  9,\n",
       "          15,  5,  1,  4,  2, 17, 18,  8,  6,  3,  3, 17,  8,  4,  4, 15, 10, 16, 10,  5,  4, 12, 14,  8,  4, 12, 18,  9,  2, 14,  8,  1,  4,\n",
       "          10,  9, 15, 20, 10,  3, 10, 10,  4, 20,  9, 10,  1,  5, 20, 14,  9,  1,  9,  1, 10,  6, 16, 18,  9,  1, 18, 12, 10, 13, 14,  8, 13,\n",
       "           4, 17,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0],\n",
       "         [11,  6,  7,  7,  7,  7,  7,  7, 16,  7, 11, 15,  8, 16, 13,  6, 14,  8, 12, 14, 18, 15, 13,  9, 10, 13, 10, 10,  9,  8, 10,  7,  1,\n",
       "           1,  6,  1, 14,  6,  4, 11,  5, 17, 18,  9,  4, 18, 11,  7, 20, 10,  6, 14, 20,  8, 11, 18,  9, 14, 10, 20,  3, 14, 14,  4, 14,  7,\n",
       "          11, 18, 20,  2,  6,  6,  3, 10, 10,  6,  4, 10, 10,  6, 15, 14, 16,  5, 16, 18,  9,  3, 13, 16, 13, 10, 20,  3, 11, 10, 15,  9, 12,\n",
       "          10, 18, 17, 10,  1, 17,  1, 17, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0],\n",
       "         [16,  1, 16, 18, 15,  8, 15,  4,  1,  9,  4,  6,  3,  2,  6,  3,  8, 10, 15, 10,  8, 15,  4, 10,  1,  4,  5,  4,  9, 10, 16,  3, 14,\n",
       "          18,  9,  8, 16,  4,  4,  1, 10, 15,  1,  3,  6,  5,  6,  3, 12, 13,  5, 20,  7,  2, 10, 18,  1,  4,  8, 10, 13,  1, 13,  6,  9, 10,\n",
       "          10,  6, 13,  2, 18, 18,  6, 20,  6,  8, 20, 20,  5,  8, 20, 16, 17, 19,  9,  6, 15, 17,  8, 20, 10,  4,  3,  8, 20, 18, 11, 13,  4,\n",
       "          20, 15,  6, 14,  6,  8,  6, 16,  9,  8,  8,  9,  9, 18,  1,  4, 18,  1, 10,  3,  9,  6,  2, 16, 14,  5, 15, 10,  1, 18, 10,  3, 19,\n",
       "          12, 14, 15,  1, 11,  3, 10, 20,  9,  1, 10,  6,  1, 14,  3, 10, 17,  4,  1,  4,  6, 19,  7,  5,  5,  2,  5, 14,  6,  4,  1, 17, 15,\n",
       "           9, 10,  1,  6,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0],\n",
       "         [11,  4,  1, 12, 17, 16, 16, 16,  6, 17, 18, 17,  6, 14, 15,  5,  1,  4, 15, 15, 15, 16, 10, 13, 13,  6,  1,  4, 10, 15, 14, 15, 10,\n",
       "          10,  9, 14, 10,  9,  4, 10,  2,  3, 14,  8,  6,  9,  1, 20, 16, 17, 10, 18, 14,  9,  1,  1, 10, 18,  8,  4, 13,  1,  3, 14,  1, 18,\n",
       "          16, 10,  4, 13,  3, 17, 14, 15, 14,  1, 17,  2,  8, 17, 12, 10, 16,  3,  4,  6,  4, 10, 19, 17, 17, 18, 20,  4, 10, 12, 10,  6, 18,\n",
       "          14, 12, 10, 10, 11,  5,  8,  4,  3,  8, 15, 10, 10, 10, 10, 17, 14,  1, 14, 18, 13,  6, 13, 16, 18,  4,  4, 12,  6, 10,  9, 17,  1,\n",
       "           6,  9,  6,  6,  2, 16, 13, 17,  4, 10,  4,  6,  1, 15,  5, 16,  3, 15, 10, 16, 16, 16, 12, 17,  7, 15,  5, 10,  4, 14, 10, 19,  3,\n",
       "          15, 20, 17, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0]]),\n",
       " tensor([0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = get_dls(trnds, vldds)\n",
    "next(iter(dls.train))[0][:5], next(iter(dls.train))[1][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flexible callback learner along with the useful callbacks and functions below are obtained from the [fast.ai 2022 course lesson 16](https://course.fast.ai/Lessons/lesson16.html) (see also on [GitHub](https://github.com/fastai/course22p2/blob/master/nbs/09_learner.ipynb)) and might be adapted depending on what I find most useful along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out which acceleration device is available and define a functin that sends objects to that device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k, v in x.items()}\n",
    "    return type(x)(o.to(device) for o in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that sends objects to the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping): return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list): return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): return tuple(to_cpu(list(x)))\n",
    "    res = x.detach().cpu()\n",
    "    return res.float() if res.dtype==torch.float16 else res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define exceptions that end the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a callback class that assigns an order to each callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback(): order = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to be used in the Learner as a context manager to handle callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that runs callbacks in a list of callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None: method(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the learner class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "\n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "\n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter,self.batch in enumerate(self.dl): self._one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, train, valid):\n",
    "        for self.epoch in self.epochs:\n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "\n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        # `add_cb` and `rm_cb` were added in lesson 18\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            if lr is None: lr = self.lr\n",
    "            if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(train, valid)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class that inherits from learner that has all the functions needed for training without requiring a train callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrainLearner(Learner):\n",
    "    def predict(self): self.preds = self.model(self.batch[0])\n",
    "    def get_loss(self): self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "    def backward(self): self.loss.backward()\n",
    "    def step(self): self.opt.step()\n",
    "    def zero_grad(self): self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback that assigns model and batches to the available acceleration device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a callback that runs for a single batch for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SingleBatchCB(Callback):\n",
    "    order = 1\n",
    "    def after_batch(self, learn): raise CancelFitException()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training callback that provides the learner with all functions necessary for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1): self.n_inp = n_inp\n",
    "    def predict(self, learn): learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "    def get_loss(self, learn): learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a metrics callback that facilitates calculation of metrics along with a progress callback that enables the display of metrics, loss, and plots that show the training progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics[\"loss\"] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "    def after_epoch(self, learn): \n",
    "        log = {k:f\"{v.compute():.3f}\" for k, v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        log = {k: str(v) for k, v in log.items()}\n",
    "        self._log(log)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        x, y = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): self.plot = plot\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "\n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses: self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "    \n",
    "    def after_epoch(self, learn): \n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'): \n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally create a learning rate finder callback and add a function to the learner that enables usage of the learning rate finder using `learn.lr_find()` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LRFinderCB(Callback):\n",
    "    def __init__(self, gamma=1.3, max_mult=3, av_over=1): fc.store_attr()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        self.sched = ExponentialLR(learn.opt, self.gamma)\n",
    "        self.lrs, self.losses = [],[]\n",
    "        self.losses_tmp = []\n",
    "        self.count = 0\n",
    "        self.min = math.inf\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        self.count += 1\n",
    "        if not learn.training: raise CancelEpochException()\n",
    "        loss = to_cpu(learn.loss)\n",
    "        self.losses_tmp.append(loss)\n",
    "        if loss < self.min: self.min = loss\n",
    "        if math.isnan(loss) or (loss > self.min*self.max_mult):\n",
    "            raise CancelFitException()\n",
    "        if self.count == self.av_over:\n",
    "            self.lrs.append(learn.opt.param_groups[0]['lr'])\n",
    "            self.losses.append(np.mean(self.losses_tmp))\n",
    "            self.losses_tmp = []\n",
    "            self.count = 0\n",
    "            self.sched.step()\n",
    "\n",
    "    def cleanup_fit(self, learn):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.title('Learning Rate Finder')\n",
    "        plt.xlabel('learning rate')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@fc.patch\n",
    "def lr_find(self:Learner, gamma=1.3, max_mult=3, start_lr=1e-5, max_epochs=10, av_over=1):\n",
    "    self.fit(max_epochs, lr=start_lr, cbs=LRFinderCB(gamma=gamma, max_mult=max_mult, av_over=av_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Convenient Plotting of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@fc.delegates(plt.Axes.imshow)\n",
    "def show_image(im, ax=None, figsize=None, title=None, noframe=True, **kwargs):\n",
    "    \"Show a PIL or PyTorch image on `ax`.\"\n",
    "    if fc.hasattrs(im, (\"cpu\", \"permute\")):\n",
    "        im = im.cpu()\n",
    "        if len(im.shape)==3 and im.shape[0]<5: im = im.permute(1,2,0)\n",
    "    elif not isinstance(im, np.ndarray): im=np.array(im)\n",
    "    if im.shape[-1]==1: im = im[..., 0]\n",
    "    if ax is None: _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, **kwargs)\n",
    "    if title is not None: ax.set_title(title)\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    if noframe: ax.axis('off')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@fc.delegates(plt.subplots, keep=True)\n",
    "def subplots(\n",
    "    nrows=1, # Number of rows in returned axes grid\n",
    "    ncols=1, # Number of columns in retruned axes grid\n",
    "    figsize=None, # Width, height in inches of the returned figure\n",
    "    imsize=3, # Size (in inches) of images that will be displayed in the returned figure\n",
    "    suptitle=None, # Title to be set to returned figure\n",
    "    **kwargs): # fig and axs\n",
    "    \"\"\"A figure and set of subplots to display images of `imsize` inches.\"\"\"\n",
    "    if figsize is None: figsize=(ncols*imsize, nrows*imsize)\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=figsize, **kwargs)\n",
    "    if suptitle is not None: fig.suptitle(suptitle)\n",
    "    if nrows*ncols==1: a = array([ax])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@fc.delegates(subplots)\n",
    "def get_grid(\n",
    "    n, # Number of axes\n",
    "    nrows=None, # Number of rows, defaulting to `int(math.sqrt(n))`\n",
    "    ncols=None, # Number of columns, defaulting to `ceil(n/rows)`\n",
    "    title=None, # If passed, title set to the figure\n",
    "    weight='bold', # Title font weight\n",
    "    size=14, # Title font size\n",
    "    **kwargs): # fig and axs\n",
    "    \"\"\"Return a grid of `n` axes, `nrows` by `ncols`.\"\"\"\n",
    "    if nrows: ncols = ncols or int(np.ceil(n/nrows))\n",
    "    elif ncols: nrows = nrows or int(np.ceil(n/ncols))\n",
    "    else:\n",
    "        nrows = int(math.sqrt(n))\n",
    "        ncols = int(np.ceil(n/nrows))\n",
    "    fig, axs = subplots(nrows, ncols, **kwargs)\n",
    "    for i in range(n, nrows*ncols): axs.flat[i].set_axis_off()\n",
    "    if title is not None: fig.suptitle(title, weight=weight, size=size)\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@fc.delegates(subplots)\n",
    "def show_images(\n",
    "    ims:list, # Images to show\n",
    "    nrows=1, # Number of rows in grid\n",
    "    ncols=None, # Number of columns in grid (auto-calculated if None)\n",
    "    titles=None, # Optional list of titles for each image\n",
    "    noframe=True, # Hide axes, yes or no\n",
    "    **kwargs):\n",
    "    \"\"\"Show all images `ims` as subplots with `nrows` using `titles`.\"\"\"\n",
    "    axs = get_grid(len(ims), **kwargs)[1].flat\n",
    "    for im, t, ax in zip_longest(ims, titles or [], axs): show_image(im, ax=ax, title=t, noframe=noframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Statistics using Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Hook():\n",
    "    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self))\n",
    "    def remove(self): self.hook.remove()\n",
    "    def __del__(self): self.remove()\n",
    "\n",
    "def append_stats(hook, mod, inp, outp):\n",
    "    if not hasattr(hook, 'stats'): hook.stats = ([], [])\n",
    "    acts = to_cpu(outp)\n",
    "    hook.stats[0].append(acts.mean())\n",
    "    hook.stats[1].append(acts.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Hooks(list):\n",
    "    def __init__(self, ms, f): super().__init__([Hook(m, f) for m in ms])\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()\n",
    "    def __del__(self): self.remove()\n",
    "    def __delitem__(self, i):\n",
    "        self[i].remove()\n",
    "        super().__delitem__(i)\n",
    "    def remove(self):\n",
    "        for h in self: h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HooksCallback(Callback):\n",
    "    def __init__(self, hookfunc, mod_filter=fc.noop, on_train=True, on_valid=False, mods=None):\n",
    "        fc.store_attr()\n",
    "        super().__init__()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        if self.mods: mods=self.mods\n",
    "        else: mods = fc.filter_ex(learn.model.modules(), self.mod_filter)\n",
    "        self.hooks = Hooks(mods, partial(self._hookfunc, learn))\n",
    "\n",
    "    def _hookfunc(self, learn, *args, **kwargs):\n",
    "        if (self.on_train and learn.training) or (self.on_valid and not learn.training): self.hookfunc(*args, **kwargs)\n",
    "\n",
    "    def after_fit(self, learn): self.hooks.remove()\n",
    "    def __iter__(self): return iter(self.hooks)\n",
    "    def __len__(self): return len(self.hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def append_stats(hook, mod, inp, outp):\n",
    "    if not hasattr(hook, 'stats'): hook.stats = ([], [], [])\n",
    "    acts = to_cpu(outp)\n",
    "    hook.stats[0].append(acts.mean())\n",
    "    hook.stats[1].append(acts.std())\n",
    "    hook.stats[2].append(acts.abs().histc(40, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Thanks to @ste for the initial version of the histogram plotting code\n",
    "def get_hist(h): return torch.stack(h.stats[2]).t().float().log1p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_min(h):\n",
    "    h1 = torch.stack(h.stats[2]).t().float()\n",
    "    return h1[:2].sum(0)/h1.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ActivationStats(HooksCallback):\n",
    "    def __init__(self, mod_filter=fc.noop): super().__init__(append_stats, mod_filter)\n",
    "\n",
    "    def color_dim(self, figsize=(11, 5)):\n",
    "        fig, axs = get_grid(len(self), figsize=figsize)\n",
    "        for ax, h in zip(axs.flat, self):\n",
    "            show_image(get_hist(h), ax, origin='lower')\n",
    "    \n",
    "    def dead_chart(self, figsize=(11, 5)):\n",
    "        fig, axs = get_grid(len(self), figsize=figsize)\n",
    "        for ax, h in zip(axs.flat, self):\n",
    "            ax.plot(get_min(h))\n",
    "            ax.set_ylim(0.0, 1.1)\n",
    "\n",
    "    def plot_stats(self, figsize=(10, 4)):\n",
    "        fig, axs = subplots(1, 2, figsize=figsize)\n",
    "        for h in self:\n",
    "            for i in 0, 1: axs[i].plot(h.stats[i])\n",
    "        axs[0].set_title('Means')\n",
    "        axs[1].set_title('Stdevs')\n",
    "        plt.legend(fc.L.range(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Convenient Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_ipython_hist():\n",
    "    # Code in this function mainly copied from IPython source\n",
    "    if not 'get_ipython' in globals(): return\n",
    "    ip = get_ipython()\n",
    "    user_ns = ip.user_ns\n",
    "    ip.displayhook.flush()\n",
    "    pc = ip.displayhook.prompt_count + 1\n",
    "    for n in range(1, pc): user_ns.pop('_i'+repr(n),None)\n",
    "    user_ns.update(dict(_i='',_ii='',_iii=''))\n",
    "    hm = ip.history_manager\n",
    "    hm.input_hist_parsed[:] = [''] * pc\n",
    "    hm.input_hist_raw[:] = [''] * pc\n",
    "    hm._i = hm._ii = hm._iii = hm._i00 =  ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_tb():\n",
    "    # h/t Piotr Czapla\n",
    "    if hasattr(sys, 'last_traceback'):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, 'last_traceback')\n",
    "    if hasattr(sys, 'last_type'): delattr(sys, 'last_type')\n",
    "    if hasattr(sys, 'last_value'): delattr(sys, 'last_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_mem():\n",
    "    clean_tb()\n",
    "    clean_ipython_hist()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Initialization and General Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_weights(m, leaky=0.):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear)): init.kaiming_normal_(m.weight, a=leaky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GeneralRelu(nn.Module):\n",
    "    def __init__(self, leak=None, sub=None, maxv=None):\n",
    "        super().__init__()\n",
    "        self.leak, self.sub, self.maxv = leak, sub, maxv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(x, self.leak) if self.leak is not None else F.relu(x)\n",
    "        if self.sub is not None: x -= self.sub\n",
    "        if self.maxv is not None: x.clamp_max_(self.maxv)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_genrelu = partial(GeneralRelu, leak=0.1, sub=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a single batch from `dls` to help with model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11,  6, 17,  ...,  0,  0,  0],\n",
       "         [11,  6,  3,  ...,  0,  0,  0],\n",
       "         [ 6,  6, 17,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 4,  8,  6,  ...,  0,  0,  0],\n",
       "         [10, 17,  4,  ...,  0,  0,  0],\n",
       "         [15, 16, 10,  ...,  0,  0,  0]]),\n",
       " torch.Size([32, 200]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = next(iter(dls.train))[0]\n",
    "idx, idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Convolutions Model with Skip Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a model architecture. Define functions to obtain 1D convolutional layers with an activation function and normalization and define a 1D residual block class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def conv1d(ni, nf, ks=3, stride=2, act=nn.ReLU, norm=None, bias=None):\n",
    "    if bias is None: bias = not isinstance(norm, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d))\n",
    "    layers = [nn.Conv1d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias)]\n",
    "    if norm: layers.append(norm(nf))\n",
    "    if act: layers.append(act())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def _conv1d_block(ni, nf, stride, act=nn.ReLU, norm=None, ks=3):\n",
    "    return nn.Sequential(conv1d(ni, nf, stride=1, act=act, norm=norm, ks=ks),\n",
    "                         conv1d(nf, nf, stride=stride, act=None, norm=norm, ks=ks))\n",
    "\n",
    "class ResBlock1d(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1, ks=3, act=nn.ReLU, norm=None):\n",
    "        super().__init__()\n",
    "        self.convs = _conv1d_block(ni, nf, stride=stride, ks=ks, act=act, norm=norm)\n",
    "        self.idconv = fc.noop if ni==nf else conv1d(ni, nf, stride=1, ks=1, act=None)\n",
    "        self.pool = fc.noop if stride==1 else nn.AvgPool1d(stride, ceil_mode=True)\n",
    "        self.act = act()\n",
    "\n",
    "    def forward(self, x): return self.act(self.convs(x) + self.pool(self.idconv(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class that switches the rank order from BLC to BCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Reshape(nn.Module):\n",
    "    def forward(self, x): \n",
    "        B, L, C = x.shape\n",
    "        return x.view(B, C, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 1\n",
    "n_embd = 16\n",
    "dls = get_dls(trnds, vldds, bs=32)\n",
    "\n",
    "model = nn.Sequential(nn.Embedding(vocab_size, n_embd, padding_idx=0), Reshape(),\n",
    "                      ResBlock1d(n_embd, 8, ks=15, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(8, 16, ks=13, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(16, 32, ks=11, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(32, 32, ks=9, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(32, 32, ks=7, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(32, 64, ks=5, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(64, 64, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      ResBlock1d(64, 128, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.3),\n",
    "                      nn.Flatten(1, -1),\n",
    "                      nn.Linear(128, 1),\n",
    "                      nn.Flatten(0, -1),\n",
    "                      nn.Sigmoid())\n",
    "model(idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters total: 200537\n"
     ]
    }
   ],
   "source": [
    "iw = partial(init_weights, leaky=0.1)\n",
    "model = model.apply(iw)\n",
    "metrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\n",
    "astats = ActivationStats(fc.risinstance(GeneralRelu))\n",
    "cbs = [DeviceCB(), ProgressCB(plot=False), metrics, astats]\n",
    "learn = TrainLearner(model, dls, F.binary_cross_entropy, lr=lr, cbs=cbs, opt_func=torch.optim.AdamW)\n",
    "print(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\n",
    "#learn.lr_find(start_lr=1e-4, gamma=1.05, av_over=5, max_mult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny Model Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "epochs = 5\n",
    "n_embd = 16\n",
    "dls = get_dls(trnds, vldds, bs=32)\n",
    "\n",
    "model = nn.Sequential(nn.Embedding(vocab_size, n_embd, padding_idx=0), Reshape(),\n",
    "                      ResBlock1d(n_embd, 2, ks=15, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(2, 4, ks=13, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(4, 4, ks=11, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(4, 4, ks=9, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(4, 8, ks=7, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(8, 8, ks=5, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(8, 16, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      ResBlock1d(16, 32, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n",
    "                      nn.Flatten(1, -1),\n",
    "                      nn.Linear(32, 1),\n",
    "                      nn.Flatten(0, -1),\n",
    "                      nn.Sigmoid())\n",
    "model(idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters total: 10175\n"
     ]
    }
   ],
   "source": [
    "iw = partial(init_weights, leaky=0.1)\n",
    "model = model.apply(iw)\n",
    "metrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\n",
    "astats = ActivationStats(fc.risinstance(GeneralRelu))\n",
    "cbs = [DeviceCB(), ProgressCB(plot=False), metrics]\n",
    "learn = TrainLearner(model, dls, F.binary_cross_entropy, lr=lr, cbs=cbs, opt_func=torch.optim.AdamW)\n",
    "print(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\n",
    "#learn.lr_find(start_lr=1e-4, gamma=1.05, av_over=5, max_mult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>BinaryAccuracy</th>\n",
       "      <th>BinaryMatthewsCorrCoef</th>\n",
       "      <th>BinaryAUROC</th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.514</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.476</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.527</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.553</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.542</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.687</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.534</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.686</td>\n",
       "      <td>2</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.577</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.676</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.557</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.668</td>\n",
       "      <td>3</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.621</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.651</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.639</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.637</td>\n",
       "      <td>4</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model with Skip Connections and LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer model below is adapted from the model built in Andrej Karpathy's video [Let's build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Head(nn.Module):\n",
    "    \"\"\"One head of self-attention.\"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        #self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) # comment out if used in an encoder setting\n",
    "        self.dropout = nn.Dropout(dropout) # <-- dropout added here\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, head_size)\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "        # compute affinities\n",
    "        wei = q @ k.transpose(-2, -1) * C**(-0.5) # (B, T, head_size) @ (B, head_size, T) --> (B, T, T)\n",
    "        #wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # comment out if used in an encoder setting\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei) # <-- dropout added here\n",
    "        v = self.value(x) # (B, T, head_size)\n",
    "        out = wei @ v # (B, T, T) @ (B, head_size, T) --> (B, T, head_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"A simple linear layer followed by a non-linearity.\"\"\"\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(n_embd, 4 * n_embd), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(4 * n_embd, n_embd),\n",
    "                                 nn.Dropout(dropout)) # <-- dropout added here\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multiple heads of self-attention in parallel.\"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout) # <-- dropout added here\n",
    "    def forward(self, x): \n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out)) # <-- dropout added here\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: communication (attention) followed by computation.\"\"\"\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd, padding_idx=0)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.lnf = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd * block_size, 1) # changed vocab_size to 1 for binary classification\n",
    "        self.flat = nn.Flatten(0, -1)\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C) (Batch, Time, Channel)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=self.device)) # (T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.lnf(x) # (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T * C)\n",
    "        logits = self.lm_head(x) # (B, 1)\n",
    "        return self.flat(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "block_size = 200\n",
    "epochs = 5\n",
    "n_embd = 16\n",
    "n_head = 8\n",
    "n_layer = 5\n",
    "dropout = 0.2\n",
    "\n",
    "model = TransformerModel(device='cpu')\n",
    "model(idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters total: 22929\n"
     ]
    }
   ],
   "source": [
    "dls = get_dls(trnds, vldds, bs=32)\n",
    "model = TransformerModel(device=def_device)\n",
    "metrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\n",
    "astats = ActivationStats(fc.risinstance(nn.ReLU))\n",
    "cbs = [DeviceCB(), ProgressCB(plot=False), metrics]\n",
    "learn = TrainLearner(model, dls, F.binary_cross_entropy_with_logits, lr=lr, cbs=cbs, opt_func=optim.AdamW)\n",
    "print(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\n",
    "#learn.lr_find(start_lr=1e-5, gamma=1.1, av_over=3, max_mult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>BinaryAccuracy</th>\n",
       "      <th>BinaryMatthewsCorrCoef</th>\n",
       "      <th>BinaryAUROC</th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.577</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.637</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.633</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.644</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.626</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.648</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.620</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.646</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.667</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.601</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.651</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.633</td>\n",
       "      <td>3</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.671</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.591</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.642</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.637</td>\n",
       "      <td>4</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
