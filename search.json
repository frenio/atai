[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "The example dataset is from the DeepSol paper by Khurana et al. and was obtained at https://zenodo.org/records/1162886.\n\ntrain_sqs = open('sol_data/train_src', 'r').read().splitlines()\ntrain_tgs = list(map(int, open('sol_data/train_tgt', 'r').read().splitlines()))\ntrain_sqs[:2], train_tgs[:2]\n\n(['GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERVAAKVVLSKMTLGDLRNNPVVPYETDEVTRIIQDQVNDRIHDSIKNWTVEELREWILDHKTTDADIKRVARGLTSEIIAAVTKLMSNLDLIYGAKKIRVIAHANTTIGLPGTFSARLQPNHPTDDPDGILASLMEGLTYGIGDAVIGLNPVDDSTDSVVRLLNKFEEFRSKWDVPTQTCVLAHVKTQMEAMRRGAPTGLVFQSIAGSEKGNTAFGFDGATIEEARQLALQSGAATGPNVMYFETGQGSELSSDAHFGVDQVTMEARCYGFAKKFDPFLVNTVVGFIGPEYLYDSKQVIRAGLEDHFMGKLTGISMGCDVCYTNHMKADQNDVENLSVLLTAAGCNFIMGIPHGDDVMLNYQTTGYHETATLRELFGLKPIKEFDQWMEKMGFSENGKLTSRAGDASIFLK',\n  'MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEYSKTGDAWPCVLLRKKSFEDLHKLYYICLKEKNKLLGEQYFHLQNSTKMLQHGRLKKVKLTMKRILTVLSRRAIHDQCLRAKDMLKKQEEREFYEIQKFKLNEQLLCLKHKMNILKKYNSFSLEQISLTFSIKKIENKIQQIDIILNPLRKETMYLLIPHFKYQRKYSDLPGFISWKKQNIIALRNNMSKLHRLY'],\n [1, 0])\n\n\n\nvalid_sqs = open('sol_data/val_src', 'r').read().splitlines()\nvalid_tgs = list(map(int, open('sol_data/val_tgt', 'r').read().splitlines()))\nvalid_sqs[:2], valid_tgs[:2]\n\n(['SRLYRHNLMEDVFNMENESFMQETRLMENEYSVNLPTRFYYKKRWNNGFVNIVNIFRACMVIGTPGSGKSYAIVNSYIRQLIAKGFAIYIYDYKFDDLSTIAYNSLLKNMDKYEVKPRFYVINFDDPRRSHRCNPINPEFMTDISDAYEASYTIMLNLNRTWIEKQGDFFVESPIILLAAIIWYLKIYKNGIYCTFPHAVELLNKPYSDLFTILTSYPELENYLSPFMDAWKGNAQDQLQGQIASAKIPLTRMISPQLYWVMTGNDFSLDINNPKEPKLLCVGNNPDRQNIYSAALGLYNSRIVKLINKKKQLKCAVIIDELPTIYFRGLDNLIATARSNKVGVLLGFQDFSQLTRDYGEKESKVIQNTVGNIFSGQVVGETAKTLSERFGKVLQQRQSVSINRQDVSTSINTQLDSLIPASKIANLSQGTFVGAVADNFDERIEQKIFHAEIVVDHTKISAEEKAYQKIPVINDFKDRNGNDIMMQQIQRNYDQIKADAQAIINEEMRRIKNDPELRKRLGLEDEKGKDPDKS',\n  'ATTYNAVVSKSSSDGKTFKTIADAIASAPAGSTPFVILIKNGVYNERLTITRNNLHLKGESRNGAVIAAATAAGTLKSDGSKWGTAGSSTITISAKDFSAQSLTIRNDFDFPANQAKSDSDSSKIKDTQAVALYVTKSGDRAYFKDVSLVGYQATLYVSGGRSFFSDCRISGTVDFIFGDGTALFNNCDLVSRYRADVKSGNVSGYLTAPSTNINQKYGLVITNSRVIRESDSVPAKSYGLGRPWHPTTTFSDGRYADPNAIGQTVFLNTSMDNHIYGWDKMSGKDKNGNTIWFNPEDSRFFEYKSYGAGATVSKDRRQLTDAQAAEYTQSKVLGDWTPTLP'],\n [0, 1])\n\n\n\ntest_sqs = open('sol_data/test_src', 'r').read().splitlines()\ntest_tgs = list(map(int, open('sol_data/test_tgt', 'r').read().splitlines()))\ntest_sqs[:2], test_tgs[:2]\n\n(['MLSVRIAAAVARALPRRAGLVSKNALGSSFVGTRNLHASNTRLQKTGTAEMSSILEERILGADTSVDLEETGRVLSIGDGIARVHGLRNVQAEEMVEFSSGLKGMSLNLEPDNVGVVVFGNDKLIKEGDIVKRTGAIVDVPVGDELLGRVVDALGNAIDGKGPVGSKIRRRVGLKAPGIIPRISVREPMQTGIKAVDSLVPIGRGQRELIIGDRQTGKTSIAIDTIINQKRFNDGTDEKKKLYCIYVAIGQKRSTVAQLVKRLTDADAMKYTIVVSATASDAAPLQYLAPYSGCSMGEYFRDNGKHALIIYDDLSKQAVAYRQMSLLLRRPPGREAYPGDVFYLHSRLLERAAKMNDSFGGGSLTALPVIETQAGDVSAYIPTNVISITDGQIFLETELFYKGIRPAINVGLSVSRVGSAAQTRAMKQVAGTMKLELAQYREVAAFAQFGSDLDAATQQLLSRGVRLTELLKQGQYSPMAIEEQVAVIYAGVRGYLDKLEPSKITKFESAFLSHVVSQHQSLLGNIRSDGKISEQSDAKLKEIVTNFLAGFEP',\n  'MDHMISENGETSAEGSICGYDSLHQLLSANLKPELYQEVNRLLLGRNCGRSLEQIVLPESAKALSSKHDFDLQAASFSADKEQMRNPRVVRVGLIQNSIALPTTAPFSDQTRGIFDKLKPIIDAAGVAGVNILCLQEAWTMPFAFCTRERRWCEFAEPVDGESTKFLQELAKKYNMVIVSPILERDIDHGEVLWNTAVIIGNNGNIIGKHRKNHIPRVGDFNESTYYMEGDTGHPVFETVFGKIAVNICYGRHHPLNWLAFGLNGAEIVFNPSATVGELSEPMWPIEARNAAIANSYFVGSINRVGTEVFPNPFTSGDGKPQHNDFGHFYGSSHFSAPDASCTPSLSRYKDGLLISDMDLNLCRQYKDKWGFRMTARYEVYADLLAKYIKPDFKPQVVSDPLLHKNST'],\n [1, 1])\n\n\n\nlen(train_sqs), len(train_tgs), len(valid_sqs), len(valid_tgs), len(test_sqs), len(test_tgs)\n\n(62478, 62478, 6942, 6942, 1999, 1999)\n\n\nCreate a sorted list of amino acid sequences aas including an empty string for padding and determine the size of the vocabulary.\n\naas = sorted(list(set(\"\".join(train_sqs))) + [\"\"])\nvocab_size = len(aas)\naas, vocab_size\n\n(['',\n  'A',\n  'C',\n  'D',\n  'E',\n  'F',\n  'G',\n  'H',\n  'I',\n  'K',\n  'L',\n  'M',\n  'N',\n  'P',\n  'Q',\n  'R',\n  'S',\n  'T',\n  'V',\n  'W',\n  'Y'],\n 21)\n\n\nCreate dictionaries that translate between string and integer representations of amino acids and define the corresponding encode and decode functions.\n\nstr2int = {aa:i for i, aa in enumerate(aas)}\nint2str = {i:aa for i, aa in enumerate(aas)}\nencode = lambda s: [str2int[aa] for aa in s]\ndecode = lambda l: ''.join([int2str[i] for i in l])\n\nprint(encode(\"AYWCCCGGGHH\"))\nprint(decode(encode(\"AYWCCCGGGHH\")))\n\n[1, 20, 19, 2, 2, 2, 6, 6, 6, 7, 7]\nAYWCCCGGGHH\n\n\nFigure out what the lengths of amino acid sequences in the dataset are and inspect the longest sequence.\n\ntrain_lens = list(map(len, train_sqs))\nmax(train_lens)\n\n1691\n\n\n\nlongest = train_sqs[np.argmax(train_lens)]\nlongest\n\n'MSGEVRLRQLEQFILDGPAQTNGQCFSVETLLDILICLYDECNNSPLRREKNILEYLEWAKPFTSKVKQMRLHREDFEILKVIGRGAFGEVAVVKLKNADKVFAMKILNKWEMLKRAETACFREERDVLVNGDNKWITTLHYAFQDDNNLYLVMDYYVGGDLLTLLSKFEDRLPEDMARFYLAEMVIAIDSVHQLHYVHRDIKPDNILMDMNGHIRLADFGSCLKLMEDGTVQSSVAVGTPDYISPEILQAMEDGKGRYGPECDWWSLGVCMYEMLYGETPFYAESLVETYGKIMNHKERFQFPAQVTDVSENAKDLIRRLICSREHRLGQNGIEDFKKHPFFSGIDWDNIRNCEAPYIPEVSSPTDTSNFDVDDDCLKNSETMPPPTHTAFSGHHLPFVGFTYTSSCVLSDRSCLRVTAGPTSLDLDVNVQRTLDNNLATEAYERRIKRLEQEKLELSRKLQESTQTVQALQYSTVDGPLTASKDLEIKNLKEEIEKLRKQVTESSHLEQQLEEANAVRQELDDAFRQIKAYEKQIKTLQQEREDLNKELVQASERLKNQSKELKDAHCQRKLAMQEFMEINERLTELHTQKQKLARHVRDKEEEVDLVMQKVESLRQELRRTERAKKELEVHTEALAAEASKDRKLREQSEHYSKQLENELEGLKQKQISYSPGVCSIEHQQEITKLKTDLEKKSIFYEEELSKREGIHANEIKNLKKELHDSEGQQLALNKEIMILKDKLEKTRRESQSEREEFESEFKQQYEREKVLLTEENKKLTSELDKLTTLYENLSIHNQQLEEEVKDLADKKESVAHWEAQITEIIQWVSDEKDARGYLQALASKMTEELEALRNSSLGTRATDMPWKMRRFAKLDMSARLELQSALDAEIRAKQAIQEELNKVKASNIITECKLKDSEKKNLELLSEIEQLIKDTEELRSEKGIEHQDSQHSFLAFLNTPTDALDQFERKTHQFFVKSFTTPTKCHQCTSLMVGLIRQGCSCEVCGFSCHITCVNKAPTTCPVPPEQTKGPLGIDPQKGIGTAYEGHVRIPKPAGVKKGWQRALAIVCDFKLFLYDIAEGKASQPSVVISQVIDMRDEEFSVSSVLASDVIHASRKDIPCIFRVTASQLSASNNKCSILMLADTENEKNKWVGVLSELHKILKKNKFRDRSVYVPKEAYDSTLPLIKTTQAAAIIDHERIALGNEEGLFVVHVTKDEIIRVGDNKKIHQIELIPNDQLVAVISGRNRHVRLFPMSALDGRETDFYKLSETKGCQTVTSGKVRHGALTCLCVAMKRQVLCYELFQSKTRHRKFKEIQVPYNVQWMAIFSEQLCVGFQSGFLRYPLNGEGNPYSMLHSNDHTLSFIAHQPMDAICAVEISSKEYLLCFNSIGIYTDCQGRRSRQQELMWPANPSSCCYNAPYLSVYSENAVDIFDVNSMEWIQTLPLKKVRPLNNEGSLNLLGLETIRLIYFKNKMAEGDELVVPETSDNSRKQMVRNINNKRRYSFRVPEEERMQQRREMLRDPEMRNKLISNPTNFNHIAHMGPGDGIQILKDLPMNPRPQESRTVFSGSVSIPSITKSRPEPGRSMSASSGLSARSSAQNGSALKREFSGGSYSAKRQPMPSPSEGSLSSGGMDQGSDAPARDFDGEDSDSPRHSTASNSSNLSSPPSPVSPRKTKSLSLESTDRGSWDP'\n\n\nCheck how many sequences in the training set are longer than 1200 amino acids.\n\nlong_sqs = []\nfor sq in train_sqs:\n    if len(sq) &gt; 1200:\n        long_sqs.append(sq)\nlen(long_sqs)\n\n132\n\n\nCreate a function that drops all sequences above a chosen threshold and also returns a list of indices of the sequences that meet the threshold that can be used to obtain the correct labels.\n\ndef drop_long_sqs(sqs, threshold=1200):\n    new_sqs = []\n    idx = []\n    for i, sq in enumerate(sqs):\n        if len(sq) &lt;= threshold:\n            new_sqs.append(sq)\n            idx.append(i)\n    return new_sqs, idx\n\nDrop all sequences above your threshold.\n\ntrnsqs, trnidx = drop_long_sqs(train_sqs, threshold=200)\nvldsqs, vldidx = drop_long_sqs(valid_sqs, threshold=200)\ntstsqs, tstidx = drop_long_sqs(test_sqs, threshold=200)\n\n\nlen(trnidx), len(vldidx), len(tstidx)\n\n(18066, 1971, 699)\n\n\nMake sure that it worked.\n\ntrnls = map(len, trnsqs)\nvldls = map(len, vldsqs)\ntstls = map(len, tstsqs)\nmax(trnls), max(vldls), max(tstls)\n\n(200, 200, 200)\n\n\nCreate a function for zero padding all sequences.\n\ndef zero_pad(sq, length=1200):\n    new_sq = sq.copy()\n    if len(new_sq) &lt; length:\n        new_sq.extend([0] * (length-len(new_sq)))\n    return new_sq\n\nNow encode and zero pad all sequences and make sure that it worked out correctly.\n\ntrn = list(map(encode, trnsqs))\nvld = list(map(encode, vldsqs))\ntst = list(map(encode, tstsqs))\nprint(f\"Length of the first two sequences before zero padding: {len(trn[0])}, {len(trn[1])}\")\ntrn = list(map(partial(zero_pad, length=200), trn))\nvld = list(map(partial(zero_pad, length=200), vld))\ntst = list(map(partial(zero_pad, length=200), tst))\nprint(f\"Length of the first two sequences after zero padding:  {len(trn[0])}, {len(trn[1])}\");\n\nLength of the first two sequences before zero padding: 116, 135\nLength of the first two sequences after zero padding:  200, 200\n\n\nConvert the data to torch.tensors unsing dtype=torch.int64 and check for correctness.\n\ntrntns = torch.tensor(trn, dtype=torch.int64)\nvldtns = torch.tensor(vld, dtype=torch.int64)\ntsttns = torch.tensor(tst, dtype=torch.int64)\ntrntns.shape, trntns[0]\n\n(torch.Size([18066, 200]),\n tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]))\n\n\n\ntrntns.shape, vldtns.shape, tsttns.shape\n\n(torch.Size([18066, 200]), torch.Size([1971, 200]), torch.Size([699, 200]))\n\n\nObtain the correct labels using the lists of indices obtained from the drop_long_sqs function and convert the lists of labels to tensors in torch.float32 format.\n\ntrnlbs = torch.tensor(train_tgs, dtype=torch.float32)[trnidx]\nvldlbs = torch.tensor(valid_tgs, dtype=torch.float32)[vldidx]\ntstlbs = torch.tensor(test_tgs, dtype=torch.float32)[tstidx]\ntrnlbs.shape, vldlbs.shape, tstlbs.shape\n\n(torch.Size([18066]), torch.Size([1971]), torch.Size([699]))\n\n\n\ntrnlbs.sum().item()/trnlbs.shape[0], vldlbs.sum().item()/vldlbs.shape[0], tstlbs.sum().item()/tstlbs.shape[0]\n\n(0.4722129967895494, 0.4657534246575342, 0.5665236051502146)\n\n\nAbove ratios tell us that there are slightly less than half soluble proteins in the training an validation data, and slightly more than half in the test set.",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#load-protein-solubility-data",
    "href": "core.html#load-protein-solubility-data",
    "title": "core",
    "section": "",
    "text": "The example dataset is from the DeepSol paper by Khurana et al. and was obtained at https://zenodo.org/records/1162886.\n\ntrain_sqs = open('sol_data/train_src', 'r').read().splitlines()\ntrain_tgs = list(map(int, open('sol_data/train_tgt', 'r').read().splitlines()))\ntrain_sqs[:2], train_tgs[:2]\n\n(['GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERVAAKVVLSKMTLGDLRNNPVVPYETDEVTRIIQDQVNDRIHDSIKNWTVEELREWILDHKTTDADIKRVARGLTSEIIAAVTKLMSNLDLIYGAKKIRVIAHANTTIGLPGTFSARLQPNHPTDDPDGILASLMEGLTYGIGDAVIGLNPVDDSTDSVVRLLNKFEEFRSKWDVPTQTCVLAHVKTQMEAMRRGAPTGLVFQSIAGSEKGNTAFGFDGATIEEARQLALQSGAATGPNVMYFETGQGSELSSDAHFGVDQVTMEARCYGFAKKFDPFLVNTVVGFIGPEYLYDSKQVIRAGLEDHFMGKLTGISMGCDVCYTNHMKADQNDVENLSVLLTAAGCNFIMGIPHGDDVMLNYQTTGYHETATLRELFGLKPIKEFDQWMEKMGFSENGKLTSRAGDASIFLK',\n  'MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEYSKTGDAWPCVLLRKKSFEDLHKLYYICLKEKNKLLGEQYFHLQNSTKMLQHGRLKKVKLTMKRILTVLSRRAIHDQCLRAKDMLKKQEEREFYEIQKFKLNEQLLCLKHKMNILKKYNSFSLEQISLTFSIKKIENKIQQIDIILNPLRKETMYLLIPHFKYQRKYSDLPGFISWKKQNIIALRNNMSKLHRLY'],\n [1, 0])\n\n\n\nvalid_sqs = open('sol_data/val_src', 'r').read().splitlines()\nvalid_tgs = list(map(int, open('sol_data/val_tgt', 'r').read().splitlines()))\nvalid_sqs[:2], valid_tgs[:2]\n\n(['SRLYRHNLMEDVFNMENESFMQETRLMENEYSVNLPTRFYYKKRWNNGFVNIVNIFRACMVIGTPGSGKSYAIVNSYIRQLIAKGFAIYIYDYKFDDLSTIAYNSLLKNMDKYEVKPRFYVINFDDPRRSHRCNPINPEFMTDISDAYEASYTIMLNLNRTWIEKQGDFFVESPIILLAAIIWYLKIYKNGIYCTFPHAVELLNKPYSDLFTILTSYPELENYLSPFMDAWKGNAQDQLQGQIASAKIPLTRMISPQLYWVMTGNDFSLDINNPKEPKLLCVGNNPDRQNIYSAALGLYNSRIVKLINKKKQLKCAVIIDELPTIYFRGLDNLIATARSNKVGVLLGFQDFSQLTRDYGEKESKVIQNTVGNIFSGQVVGETAKTLSERFGKVLQQRQSVSINRQDVSTSINTQLDSLIPASKIANLSQGTFVGAVADNFDERIEQKIFHAEIVVDHTKISAEEKAYQKIPVINDFKDRNGNDIMMQQIQRNYDQIKADAQAIINEEMRRIKNDPELRKRLGLEDEKGKDPDKS',\n  'ATTYNAVVSKSSSDGKTFKTIADAIASAPAGSTPFVILIKNGVYNERLTITRNNLHLKGESRNGAVIAAATAAGTLKSDGSKWGTAGSSTITISAKDFSAQSLTIRNDFDFPANQAKSDSDSSKIKDTQAVALYVTKSGDRAYFKDVSLVGYQATLYVSGGRSFFSDCRISGTVDFIFGDGTALFNNCDLVSRYRADVKSGNVSGYLTAPSTNINQKYGLVITNSRVIRESDSVPAKSYGLGRPWHPTTTFSDGRYADPNAIGQTVFLNTSMDNHIYGWDKMSGKDKNGNTIWFNPEDSRFFEYKSYGAGATVSKDRRQLTDAQAAEYTQSKVLGDWTPTLP'],\n [0, 1])\n\n\n\ntest_sqs = open('sol_data/test_src', 'r').read().splitlines()\ntest_tgs = list(map(int, open('sol_data/test_tgt', 'r').read().splitlines()))\ntest_sqs[:2], test_tgs[:2]\n\n(['MLSVRIAAAVARALPRRAGLVSKNALGSSFVGTRNLHASNTRLQKTGTAEMSSILEERILGADTSVDLEETGRVLSIGDGIARVHGLRNVQAEEMVEFSSGLKGMSLNLEPDNVGVVVFGNDKLIKEGDIVKRTGAIVDVPVGDELLGRVVDALGNAIDGKGPVGSKIRRRVGLKAPGIIPRISVREPMQTGIKAVDSLVPIGRGQRELIIGDRQTGKTSIAIDTIINQKRFNDGTDEKKKLYCIYVAIGQKRSTVAQLVKRLTDADAMKYTIVVSATASDAAPLQYLAPYSGCSMGEYFRDNGKHALIIYDDLSKQAVAYRQMSLLLRRPPGREAYPGDVFYLHSRLLERAAKMNDSFGGGSLTALPVIETQAGDVSAYIPTNVISITDGQIFLETELFYKGIRPAINVGLSVSRVGSAAQTRAMKQVAGTMKLELAQYREVAAFAQFGSDLDAATQQLLSRGVRLTELLKQGQYSPMAIEEQVAVIYAGVRGYLDKLEPSKITKFESAFLSHVVSQHQSLLGNIRSDGKISEQSDAKLKEIVTNFLAGFEP',\n  'MDHMISENGETSAEGSICGYDSLHQLLSANLKPELYQEVNRLLLGRNCGRSLEQIVLPESAKALSSKHDFDLQAASFSADKEQMRNPRVVRVGLIQNSIALPTTAPFSDQTRGIFDKLKPIIDAAGVAGVNILCLQEAWTMPFAFCTRERRWCEFAEPVDGESTKFLQELAKKYNMVIVSPILERDIDHGEVLWNTAVIIGNNGNIIGKHRKNHIPRVGDFNESTYYMEGDTGHPVFETVFGKIAVNICYGRHHPLNWLAFGLNGAEIVFNPSATVGELSEPMWPIEARNAAIANSYFVGSINRVGTEVFPNPFTSGDGKPQHNDFGHFYGSSHFSAPDASCTPSLSRYKDGLLISDMDLNLCRQYKDKWGFRMTARYEVYADLLAKYIKPDFKPQVVSDPLLHKNST'],\n [1, 1])\n\n\n\nlen(train_sqs), len(train_tgs), len(valid_sqs), len(valid_tgs), len(test_sqs), len(test_tgs)\n\n(62478, 62478, 6942, 6942, 1999, 1999)\n\n\nCreate a sorted list of amino acid sequences aas including an empty string for padding and determine the size of the vocabulary.\n\naas = sorted(list(set(\"\".join(train_sqs))) + [\"\"])\nvocab_size = len(aas)\naas, vocab_size\n\n(['',\n  'A',\n  'C',\n  'D',\n  'E',\n  'F',\n  'G',\n  'H',\n  'I',\n  'K',\n  'L',\n  'M',\n  'N',\n  'P',\n  'Q',\n  'R',\n  'S',\n  'T',\n  'V',\n  'W',\n  'Y'],\n 21)\n\n\nCreate dictionaries that translate between string and integer representations of amino acids and define the corresponding encode and decode functions.\n\nstr2int = {aa:i for i, aa in enumerate(aas)}\nint2str = {i:aa for i, aa in enumerate(aas)}\nencode = lambda s: [str2int[aa] for aa in s]\ndecode = lambda l: ''.join([int2str[i] for i in l])\n\nprint(encode(\"AYWCCCGGGHH\"))\nprint(decode(encode(\"AYWCCCGGGHH\")))\n\n[1, 20, 19, 2, 2, 2, 6, 6, 6, 7, 7]\nAYWCCCGGGHH\n\n\nFigure out what the lengths of amino acid sequences in the dataset are and inspect the longest sequence.\n\ntrain_lens = list(map(len, train_sqs))\nmax(train_lens)\n\n1691\n\n\n\nlongest = train_sqs[np.argmax(train_lens)]\nlongest\n\n'MSGEVRLRQLEQFILDGPAQTNGQCFSVETLLDILICLYDECNNSPLRREKNILEYLEWAKPFTSKVKQMRLHREDFEILKVIGRGAFGEVAVVKLKNADKVFAMKILNKWEMLKRAETACFREERDVLVNGDNKWITTLHYAFQDDNNLYLVMDYYVGGDLLTLLSKFEDRLPEDMARFYLAEMVIAIDSVHQLHYVHRDIKPDNILMDMNGHIRLADFGSCLKLMEDGTVQSSVAVGTPDYISPEILQAMEDGKGRYGPECDWWSLGVCMYEMLYGETPFYAESLVETYGKIMNHKERFQFPAQVTDVSENAKDLIRRLICSREHRLGQNGIEDFKKHPFFSGIDWDNIRNCEAPYIPEVSSPTDTSNFDVDDDCLKNSETMPPPTHTAFSGHHLPFVGFTYTSSCVLSDRSCLRVTAGPTSLDLDVNVQRTLDNNLATEAYERRIKRLEQEKLELSRKLQESTQTVQALQYSTVDGPLTASKDLEIKNLKEEIEKLRKQVTESSHLEQQLEEANAVRQELDDAFRQIKAYEKQIKTLQQEREDLNKELVQASERLKNQSKELKDAHCQRKLAMQEFMEINERLTELHTQKQKLARHVRDKEEEVDLVMQKVESLRQELRRTERAKKELEVHTEALAAEASKDRKLREQSEHYSKQLENELEGLKQKQISYSPGVCSIEHQQEITKLKTDLEKKSIFYEEELSKREGIHANEIKNLKKELHDSEGQQLALNKEIMILKDKLEKTRRESQSEREEFESEFKQQYEREKVLLTEENKKLTSELDKLTTLYENLSIHNQQLEEEVKDLADKKESVAHWEAQITEIIQWVSDEKDARGYLQALASKMTEELEALRNSSLGTRATDMPWKMRRFAKLDMSARLELQSALDAEIRAKQAIQEELNKVKASNIITECKLKDSEKKNLELLSEIEQLIKDTEELRSEKGIEHQDSQHSFLAFLNTPTDALDQFERKTHQFFVKSFTTPTKCHQCTSLMVGLIRQGCSCEVCGFSCHITCVNKAPTTCPVPPEQTKGPLGIDPQKGIGTAYEGHVRIPKPAGVKKGWQRALAIVCDFKLFLYDIAEGKASQPSVVISQVIDMRDEEFSVSSVLASDVIHASRKDIPCIFRVTASQLSASNNKCSILMLADTENEKNKWVGVLSELHKILKKNKFRDRSVYVPKEAYDSTLPLIKTTQAAAIIDHERIALGNEEGLFVVHVTKDEIIRVGDNKKIHQIELIPNDQLVAVISGRNRHVRLFPMSALDGRETDFYKLSETKGCQTVTSGKVRHGALTCLCVAMKRQVLCYELFQSKTRHRKFKEIQVPYNVQWMAIFSEQLCVGFQSGFLRYPLNGEGNPYSMLHSNDHTLSFIAHQPMDAICAVEISSKEYLLCFNSIGIYTDCQGRRSRQQELMWPANPSSCCYNAPYLSVYSENAVDIFDVNSMEWIQTLPLKKVRPLNNEGSLNLLGLETIRLIYFKNKMAEGDELVVPETSDNSRKQMVRNINNKRRYSFRVPEEERMQQRREMLRDPEMRNKLISNPTNFNHIAHMGPGDGIQILKDLPMNPRPQESRTVFSGSVSIPSITKSRPEPGRSMSASSGLSARSSAQNGSALKREFSGGSYSAKRQPMPSPSEGSLSSGGMDQGSDAPARDFDGEDSDSPRHSTASNSSNLSSPPSPVSPRKTKSLSLESTDRGSWDP'\n\n\nCheck how many sequences in the training set are longer than 1200 amino acids.\n\nlong_sqs = []\nfor sq in train_sqs:\n    if len(sq) &gt; 1200:\n        long_sqs.append(sq)\nlen(long_sqs)\n\n132\n\n\nCreate a function that drops all sequences above a chosen threshold and also returns a list of indices of the sequences that meet the threshold that can be used to obtain the correct labels.\n\ndef drop_long_sqs(sqs, threshold=1200):\n    new_sqs = []\n    idx = []\n    for i, sq in enumerate(sqs):\n        if len(sq) &lt;= threshold:\n            new_sqs.append(sq)\n            idx.append(i)\n    return new_sqs, idx\n\nDrop all sequences above your threshold.\n\ntrnsqs, trnidx = drop_long_sqs(train_sqs, threshold=200)\nvldsqs, vldidx = drop_long_sqs(valid_sqs, threshold=200)\ntstsqs, tstidx = drop_long_sqs(test_sqs, threshold=200)\n\n\nlen(trnidx), len(vldidx), len(tstidx)\n\n(18066, 1971, 699)\n\n\nMake sure that it worked.\n\ntrnls = map(len, trnsqs)\nvldls = map(len, vldsqs)\ntstls = map(len, tstsqs)\nmax(trnls), max(vldls), max(tstls)\n\n(200, 200, 200)\n\n\nCreate a function for zero padding all sequences.\n\ndef zero_pad(sq, length=1200):\n    new_sq = sq.copy()\n    if len(new_sq) &lt; length:\n        new_sq.extend([0] * (length-len(new_sq)))\n    return new_sq\n\nNow encode and zero pad all sequences and make sure that it worked out correctly.\n\ntrn = list(map(encode, trnsqs))\nvld = list(map(encode, vldsqs))\ntst = list(map(encode, tstsqs))\nprint(f\"Length of the first two sequences before zero padding: {len(trn[0])}, {len(trn[1])}\")\ntrn = list(map(partial(zero_pad, length=200), trn))\nvld = list(map(partial(zero_pad, length=200), vld))\ntst = list(map(partial(zero_pad, length=200), tst))\nprint(f\"Length of the first two sequences after zero padding:  {len(trn[0])}, {len(trn[1])}\");\n\nLength of the first two sequences before zero padding: 116, 135\nLength of the first two sequences after zero padding:  200, 200\n\n\nConvert the data to torch.tensors unsing dtype=torch.int64 and check for correctness.\n\ntrntns = torch.tensor(trn, dtype=torch.int64)\nvldtns = torch.tensor(vld, dtype=torch.int64)\ntsttns = torch.tensor(tst, dtype=torch.int64)\ntrntns.shape, trntns[0]\n\n(torch.Size([18066, 200]),\n tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]))\n\n\n\ntrntns.shape, vldtns.shape, tsttns.shape\n\n(torch.Size([18066, 200]), torch.Size([1971, 200]), torch.Size([699, 200]))\n\n\nObtain the correct labels using the lists of indices obtained from the drop_long_sqs function and convert the lists of labels to tensors in torch.float32 format.\n\ntrnlbs = torch.tensor(train_tgs, dtype=torch.float32)[trnidx]\nvldlbs = torch.tensor(valid_tgs, dtype=torch.float32)[vldidx]\ntstlbs = torch.tensor(test_tgs, dtype=torch.float32)[tstidx]\ntrnlbs.shape, vldlbs.shape, tstlbs.shape\n\n(torch.Size([18066]), torch.Size([1971]), torch.Size([699]))\n\n\n\ntrnlbs.sum().item()/trnlbs.shape[0], vldlbs.sum().item()/vldlbs.shape[0], tstlbs.sum().item()/tstlbs.shape[0]\n\n(0.4722129967895494, 0.4657534246575342, 0.5665236051502146)\n\n\nAbove ratios tell us that there are slightly less than half soluble proteins in the training an validation data, and slightly more than half in the test set.",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#dataset-and-dataloaders",
    "href": "core.html#dataset-and-dataloaders",
    "title": "core",
    "section": "Dataset and DataLoaders",
    "text": "Dataset and DataLoaders\nCreate a Dataset class and combine tokens and labels into datasets.\n\nsource\n\nDataset\n\n Dataset (x, y)\n\nCombines features and lables in a dataset.\n\ntrnds = Dataset(trntns, trnlbs)\nvldds = Dataset(vldtns, vldlbs)\ntstds = Dataset(tsttns, tstlbs)\ntrnds[0]\n\n(tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]),\n tensor(0.))\n\n\nDefine a DataLoaders class and a function that creates your DataLoaders given a train dataset, a valid dataset, and a batch size.\n\nsource\n\n\nDataLoaders\n\n DataLoaders (*dls)\n\nCombines training and validation data in a DataLoaders object that can be passed to a learner.\n\nsource\n\n\nget_dls\n\n get_dls (train_ds, valid_ds, bs=32)\n\nTurn training and validation set into a DataLoaders object.\nGet the DataLoaders object and test it.\n\ndls = get_dls(trnds, vldds)\nnext(iter(dls.train))[0][:5], next(iter(dls.train))[1][:5]\n\n(tensor([[ 4, 16, 20,  1,  8,  5, 16, 10, 12,  1, 14,  5,  3,  1, 10, 17,  8, 12,  9,  1, 15,  9, 10, 20, 15,  6,  9, 17, 15, 10, 10, 14,  6,\n          14, 15,  8,  4, 10, 16,  3, 19, 13,  4, 17, 16, 18,  4, 15, 17,  4,  5, 20, 15, 20, 10, 10, 12,  9, 12, 10,  1, 14, 11, 12,  1,  7,\n          19,  1, 16, 10, 16,  5, 16,  6,  9,  1, 15, 13, 13,  9, 18,  8,  3, 14, 13, 16,  8,  4,  8, 10, 10,  1, 19, 11, 15,  4, 14, 13, 12,\n          15,  8,  6, 20,  1, 13, 18,  3, 16, 10, 13, 16,  3,  1,  7, 18, 10, 20, 18, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0],\n         [ 6,  8,  3, 13,  5, 17, 11, 10,  7,  8,  4,  5,  8, 17,  3, 10,  6,  1,  9, 18, 17, 18,  3, 18,  4, 16,  1,  3,  9, 10, 10,  3, 18,\n          14, 15, 14, 20,  6, 15, 10,  6, 19, 17, 16,  6,  4, 18, 13, 18,  6,  6, 20, 14,  5, 13, 10,  4, 12,  4, 13,  3,  5,  3, 19, 16, 10,\n           8,  6,  1, 15,  9, 19, 17, 12, 13,  4,  6,  4,  4, 11,  8, 10,  7, 15,  6,  7,  1, 20, 15, 15, 15,  4, 10,  4,  1, 18,  3, 16, 15,\n           9, 11,  9, 10, 13,  1,  1, 18,  9, 20, 16, 15,  6,  1,  9, 12, 17,  3, 13,  4,  7, 18, 15,  4,  9,  1,  3,  6,  4,  5,  4, 20, 18,\n          17, 10,  1,  8,  5, 15,  6,  6,  9, 15, 14,  4, 15, 20,  1, 18, 13,  6, 16, 12, 15, 13, 14,  1,  6,  1, 13,  1, 15, 16,  1,  1, 17,\n          15,  1, 14,  6,  1, 15, 13,  6,  1, 18,  1, 18, 14,  3,  4,  4, 17, 13,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0],\n         [ 6, 13,  6, 16, 11,  1,  3, 18,  1,  3, 13, 16, 16,  4, 10,  8, 12,  4, 10, 15,  1, 10, 18, 18, 16,  6, 16,  6, 10, 18, 13, 10,  3,\n           4, 15,  9, 18,  7, 17, 18, 18,  4, 12, 11, 17,  3,  1,  5, 15,  7, 10,  4, 16,  8, 16, 15, 12, 13,  5,  1,  3, 13, 16, 14, 13, 20,\n          20, 16,  6,  1, 11, 15,  5, 20,  9,  1,  9,  2, 10, 15,  3,  9, 15,  2, 18, 18,  1, 20, 10, 10, 19, 15, 14, 16, 14,  8, 17,  9, 16,\n          19, 19,  4,  1, 15,  3, 12, 17,  8, 16, 12, 11, 10,  1, 13,  2,  4, 15, 17,  5, 10, 14,  3, 20, 12,  3, 18, 11, 18,  4, 20, 11, 17,\n          16,  5,  1, 18, 13, 10,  3, 10, 15, 16,  5, 17, 19, 15, 13, 13, 16, 17, 14, 14, 10,  4, 18, 15,  6, 10, 18, 12,  7, 18,  5, 18, 16,\n          16,  8, 17,  6,  1, 18,  8, 12, 10, 20,  9,  6,  9, 14,  8, 10, 10,  6,  5,  4,  4,  1,  4, 16, 10,  8, 14, 14,  6, 18, 18,  4, 10,\n          18,  4],\n         [11,  8, 16,  9, 17, 16,  8, 10, 10, 10,  6,  5,  1,  2,  1,  1, 18,  6,  1, 12, 20,  8,  4, 16,  1,  8,  5,  9,  5,  3,  3, 16,  2,\n           4, 13, 10,  4,  4, 13, 15,  9, 13,  4, 18,  1,  9,  2, 20,  4, 13, 16, 17, 16, 10, 13,  9, 17, 10,  4,  4, 20, 15,  1, 11,  6, 20,\n           3, 19,  6,  4,  5, 18,  7,  3,  3,  9,  1,  3, 14,  1, 13,  4,  6, 10,  3,  4, 18,  5, 17, 20, 13, 11, 18, 13,  5,  8,  6, 11, 16,\n          10, 10,  1, 16,  9,  9,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0],\n         [12, 10, 10,  3,  3,  1, 18,  9, 15,  8, 16,  4,  3, 13, 13,  2,  9,  2, 13, 17,  9,  5,  2, 18,  4, 15, 10, 16, 14,  6, 15, 20, 15,\n          18,  6,  4,  9,  8, 10,  5,  8, 15, 11, 10,  7, 12,  9,  7, 18, 11, 18, 15, 18,  6,  6,  6, 19,  4, 17,  5,  1,  6, 20, 10, 10,  9,\n           7,  3, 13,  2, 15, 11, 10, 14,  8, 16, 15, 18,  3,  6,  9, 17, 16, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0]]),\n tensor([1., 1., 1., 0., 1.]))",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#learner-framework-and-callbacks",
    "href": "core.html#learner-framework-and-callbacks",
    "title": "core",
    "section": "Learner Framework and Callbacks",
    "text": "Learner Framework and Callbacks\nThe flexible callback learner along with the useful callbacks and functions below are obtained from the fast.ai 2022 course lesson 16 (see also on GitHub) and might be adapted depending on what I find most useful along the way.\nFigure out which acceleration device is available and define a functin that sends objects to that device.\n\nsource\n\nto_device\n\n to_device (x, device='cpu')\n\nDefine a function that sends objects to the cpu.\n\nsource\n\n\nto_cpu\n\n to_cpu (x)\n\nDefine exceptions that end the learning process.\n\nsource\n\n\nCancelEpochException\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nCancelBatchException\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nCancelFitException\nCommon base class for all non-exit exceptions.\nDefine a callback class that assigns an order to each callback.\n\nsource\n\n\nCallback\n\n Callback ()\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine a class to be used in the Learner as a context manager to handle callbacks.\n\nsource\n\n\nwith_cbs\n\n with_cbs (nm)\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine a function that runs callbacks in a list of callbacks.\n\nsource\n\n\nrun_cbs\n\n run_cbs (cbs, method_nm, learn=None)\n\nDefine the learner class.\n\nsource\n\n\nLearner\n\n Learner (model, dls=(0,), loss_func=&lt;function mse_loss&gt;, lr=0.1,\n          cbs=None, opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine a class that inherits from learner that has all the functions needed for training without requiring a train callback.\n\nsource\n\n\nTrainLearner\n\n TrainLearner (model, dls=(0,), loss_func=&lt;function mse_loss&gt;, lr=0.1,\n               cbs=None, opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\nCreate a callback that assigns model and batches to the available acceleration device.\n\nsource\n\n\nDeviceCB\n\n DeviceCB (device='cpu')\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine a callback that runs for a single batch for testing purposes.\n\nsource\n\n\nSingleBatchCB\n\n SingleBatchCB ()\n\nInitialize self. See help(type(self)) for accurate signature.\nCreate a training callback that provides the learner with all functions necessary for training.\n\nsource\n\n\nTrainCB\n\n TrainCB (n_inp=1)\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine scheduler callbacks that adjust the learning rate according to a schedule along with a callback that tracks the learining rate applied on every step.\n\nsource\n\n\nRecorderCB\n\n RecorderCB (**d)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nEpochSchedCB\n\n EpochSchedCB (sched=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nBatchSchedCB\n\n BatchSchedCB (sched=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nBaseSchedCB\n\n BaseSchedCB (sched=None)\n\nInitialize self. See help(type(self)) for accurate signature.\nDefine a metrics callback that facilitates calculation of metrics along with a progress callback that enables the display of metrics, loss, and plots that show the training progress during training.\n\nsource\n\n\nMetricsCB\n\n MetricsCB (*ms, **metrics)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nProgressCB\n\n ProgressCB (plot=False)\n\nInitialize self. See help(type(self)) for accurate signature.\nFinally create a learning rate finder callback and add a function to the learner that enables usage of the learning rate finder using learn.lr_find() syntax.\n\nsource\n\n\nLRFinderCB\n\n LRFinderCB (gamma=1.3, max_mult=3, av_over=1)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:str|None=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#functions-for-convenient-plotting-of-images",
    "href": "core.html#functions-for-convenient-plotting-of-images",
    "title": "core",
    "section": "Functions for Convenient Plotting of Images",
    "text": "Functions for Convenient Plotting of Images\n/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Other Parameters\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section See Also\n  else: warn(msg)\n\nsource\n\nshow_image\n\n show_image (im, ax=None, figsize=None, title=None, noframe=True,\n             cmap=None, norm=None, aspect=None, interpolation=None,\n             alpha=None, vmin=None, vmax=None, origin=None, extent=None,\n             interpolation_stage=None, filternorm=True, filterrad=4.0,\n             resample=None, url=None, data=None)\n\nShow a PIL or PyTorch image on ax.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim\n\n\n\n\n\nax\nNoneType\nNone\n\n\n\nfigsize\nNoneType\nNone\n\n\n\ntitle\nNoneType\nNone\n\n\n\nnoframe\nbool\nTrue\n\n\n\ncmap\nNoneType\nNone\nThe Colormap instance or registered colormap name used to map scalar datato colors.This parameter is ignored if X is RGB(A).\n\n\nnorm\nNoneType\nNone\nThe normalization method used to scale scalar data to the [0, 1] rangebefore mapping to colors using cmap. By default, a linear scaling isused, mapping the lowest value to 0 and the highest to 1.If given, this can be one of the following:- An instance of .Normalize or one of its subclasses (see :ref:colormapnorms).- A scale name, i.e. one of “linear”, “log”, “symlog”, “logit”, etc. For a list of available scales, call matplotlib.scale.get_scale_names(). In that case, a suitable .Normalize subclass is dynamically generated and instantiated.This parameter is ignored if X is RGB(A).\n\n\naspect\nNoneType\nNone\nThe aspect ratio of the Axes. This parameter is particularlyrelevant for images since it determines whether data pixels aresquare.This parameter is a shortcut for explicitly calling.Axes.set_aspect. See there for further details.- ‘equal’: Ensures an aspect ratio of 1. Pixels will be square (unless pixel sizes are explicitly made non-square in data coordinates using extent).- ‘auto’: The Axes is kept fixed and the aspect is adjusted so that the data fit in the Axes. In general, this will result in non-square pixels.Normally, None (the default) means to use :rc:image.aspect. However, ifthe image uses a transform that does not contain the axes data transform,then None means to not modify the axes aspect at all (in that case, directlycall .Axes.set_aspect if desired).\n\n\ninterpolation\nNoneType\nNone\nThe interpolation method used.Supported values are ‘none’, ‘antialiased’, ‘nearest’, ‘bilinear’,‘bicubic’, ‘spline16’, ‘spline36’, ‘hanning’, ‘hamming’, ‘hermite’,‘kaiser’, ‘quadric’, ‘catrom’, ‘gaussian’, ‘bessel’, ‘mitchell’,‘sinc’, ‘lanczos’, ‘blackman’.The data X is resampled to the pixel size of the image on thefigure canvas, using the interpolation method to either up- ordownsample the data.If interpolation is ‘none’, then for the ps, pdf, and svgbackends no down- or upsampling occurs, and the image data ispassed to the backend as a native image. Note that different ps,pdf, and svg viewers may display these raw pixels differently. Onother backends, ‘none’ is the same as ‘nearest’.If interpolation is the default ‘antialiased’, then ‘nearest’interpolation is used if the image is upsampled by more than afactor of three (i.e. the number of display pixels is at leastthree times the size of the data array). If the upsampling rate issmaller than 3, or the image is downsampled, then ‘hanning’interpolation is used to act as an anti-aliasing filter, unless theimage happens to be upsampled by exactly a factor of two or one.See:doc:/gallery/images_contours_and_fields/interpolation_methodsfor an overview of the supported interpolation methods, and:doc:/gallery/images_contours_and_fields/image_antialiasing fora discussion of image antialiasing.Some interpolation methods require an additional radius parameter,which can be set by filterrad. Additionally, the antigrain imageresize filter is controlled by the parameter filternorm.\n\n\nalpha\nNoneType\nNone\nThe alpha blending value, between 0 (transparent) and 1 (opaque).If alpha is an array, the alpha blending values are applied pixelby pixel, and alpha must have the same shape as X.\n\n\nvmin\nNoneType\nNone\n\n\n\nvmax\nNoneType\nNone\n\n\n\norigin\nNoneType\nNone\nPlace the [0, 0] index of the array in the upper left or lowerleft corner of the Axes. The convention (the default) ‘upper’ istypically used for matrices and images.Note that the vertical axis points upward for ‘lower’but downward for ‘upper’.See the :ref:imshow_extent tutorial forexamples and a more detailed description.\n\n\nextent\nNoneType\nNone\nThe bounding box in data coordinates that the image will fill.These values may be unitful and match the units of the Axes.The image is stretched individually along x and y to fill the box.The default extent is determined by the following conditions.Pixels have unit size in data coordinates. Their centers are oninteger coordinates, and their center coordinates range from 0 tocolumns-1 horizontally and from 0 to rows-1 vertically.Note that the direction of the vertical axis and thus the defaultvalues for top and bottom depend on origin:- For origin == 'upper' the default is (-0.5, numcols-0.5, numrows-0.5, -0.5).- For origin == 'lower' the default is (-0.5, numcols-0.5, -0.5, numrows-0.5).See the :ref:imshow_extent tutorial forexamples and a more detailed description.\n\n\ninterpolation_stage\nNoneType\nNone\nIf ‘data’, interpolationis carried out on the data provided by the user. If ‘rgba’, theinterpolation is carried out after the colormapping has beenapplied (visual interpolation).\n\n\nfilternorm\nbool\nTrue\nA parameter for the antigrain image resize filter (see theantigrain documentation). If filternorm is set, the filternormalizes integer values and corrects the rounding errors. Itdoesn’t do anything with the source floating point values, itcorrects only integers according to the rule of 1.0 which meansthat any sum of pixel weights must be equal to 1.0. So, thefilter function must produce a graph of the proper shape.\n\n\nfilterrad\nfloat\n4.0\nThe filter radius for filters that have a radius parameter, i.e.when interpolation is one of: ‘sinc’, ‘lanczos’ or ‘blackman’.\n\n\nresample\nNoneType\nNone\nWhen True, use a full resampling method. When False, onlyresample when the output image is larger than the input image.\n\n\nurl\nNoneType\nNone\nSet the url of the created .AxesImage. See .Artist.set_url.\n\n\ndata\nNoneType\nNone\n\n\n\n\n\nsource\n\n\nsubplots\n\n subplots (nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None,\n           sharex:\"bool|Literal['none','all','row','col']\"=False,\n           sharey:\"bool|Literal['none','all','row','col']\"=False,\n           squeeze:bool=True, width_ratios:Sequence[float]|None=None,\n           height_ratios:Sequence[float]|None=None,\n           subplot_kw:dict[str,Any]|None=None,\n           gridspec_kw:dict[str,Any]|None=None, **kwargs)\n\nA figure and set of subplots to display images of imsize inches.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnrows\nint\n1\nNumber of rows in returned axes grid\n\n\nncols\nint\n1\nNumber of columns in retruned axes grid\n\n\nfigsize\nNoneType\nNone\nWidth, height in inches of the returned figure\n\n\nimsize\nint\n3\nSize (in inches) of images that will be displayed in the returned figure\n\n\nsuptitle\nNoneType\nNone\nTitle to be set to returned figure\n\n\nsharex\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsharey\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nSequence[float] | None\nNone\n\n\n\nheight_ratios\nSequence[float] | None\nNone\n\n\n\nsubplot_kw\ndict[str, Any] | None\nNone\n\n\n\ngridspec_kw\ndict[str, Any] | None\nNone\n\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nget_grid\n\n get_grid (n, nrows=None, ncols=None, title=None, weight='bold', size=14,\n           figsize=None, imsize=3, suptitle=None,\n           sharex:\"bool|Literal['none','all','row','col']\"=False,\n           sharey:\"bool|Literal['none','all','row','col']\"=False,\n           squeeze:bool=True, width_ratios:Sequence[float]|None=None,\n           height_ratios:Sequence[float]|None=None,\n           subplot_kw:dict[str,Any]|None=None,\n           gridspec_kw:dict[str,Any]|None=None)\n\nReturn a grid of n axes, nrows by ncols.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\n\n\nNumber of axes\n\n\nnrows\nNoneType\nNone\nNumber of rows, defaulting to int(math.sqrt(n))\n\n\nncols\nNoneType\nNone\nNumber of columns, defaulting to ceil(n/rows)\n\n\ntitle\nNoneType\nNone\nIf passed, title set to the figure\n\n\nweight\nstr\nbold\nTitle font weight\n\n\nsize\nint\n14\nTitle font size\n\n\nfigsize\nNoneType\nNone\nWidth, height in inches of the returned figure\n\n\nimsize\nint\n3\nSize (in inches) of images that will be displayed in the returned figure\n\n\nsuptitle\nNoneType\nNone\nTitle to be set to returned figure\n\n\nsharex\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsharey\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nSequence[float] | None\nNone\n\n\n\nheight_ratios\nSequence[float] | None\nNone\n\n\n\nsubplot_kw\ndict[str, Any] | None\nNone\n\n\n\ngridspec_kw\ndict[str, Any] | None\nNone\n\n\n\n\n\nsource\n\n\nshow_images\n\n show_images (ims:list, nrows=1, ncols=None, titles=None, noframe=True,\n              figsize=None, imsize=3, suptitle=None,\n              sharex:\"bool|Literal['none','all','row','col']\"=False,\n              sharey:\"bool|Literal['none','all','row','col']\"=False,\n              squeeze:bool=True, width_ratios:Sequence[float]|None=None,\n              height_ratios:Sequence[float]|None=None,\n              subplot_kw:dict[str,Any]|None=None,\n              gridspec_kw:dict[str,Any]|None=None)\n\nShow all images ims as subplots with nrows using titles.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nims\nlist\n\nImages to show\n\n\nnrows\nint\n1\nNumber of rows in grid\n\n\nncols\nNoneType\nNone\nNumber of columns in grid (auto-calculated if None)\n\n\ntitles\nNoneType\nNone\nOptional list of titles for each image\n\n\nnoframe\nbool\nTrue\nHide axes, yes or no\n\n\nfigsize\nNoneType\nNone\nWidth, height in inches of the returned figure\n\n\nimsize\nint\n3\nSize (in inches) of images that will be displayed in the returned figure\n\n\nsuptitle\nNoneType\nNone\nTitle to be set to returned figure\n\n\nsharex\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsharey\nbool | Literal[‘none’, ‘all’, ‘row’, ‘col’]\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nSequence[float] | None\nNone\n\n\n\nheight_ratios\nSequence[float] | None\nNone\n\n\n\nsubplot_kw\ndict[str, Any] | None\nNone\n\n\n\ngridspec_kw\ndict[str, Any] | None\nNone",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#activation-statistics-using-hooks",
    "href": "core.html#activation-statistics-using-hooks",
    "title": "core",
    "section": "Activation Statistics using Hooks",
    "text": "Activation Statistics using Hooks\n\nsource\n\nappend_stats\n\n append_stats (hook, mod, inp, outp)\n\n\nsource\n\n\nHook\n\n Hook (m, f)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nHooks\n\n Hooks (ms, f)\n\n*Built-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list. The argument must be an iterable if specified.*\n\nsource\n\n\nHooksCallback\n\n HooksCallback (hookfunc, mod_filter=&lt;function noop&gt;, on_train=True,\n                on_valid=False, mods=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nappend_stats\n\n append_stats (hook, mod, inp, outp)\n\n\nsource\n\n\nget_hist\n\n get_hist (h)\n\n\nsource\n\n\nget_min\n\n get_min (h)\n\n\nsource\n\n\nActivationStats\n\n ActivationStats (mod_filter=&lt;function noop&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#functions-for-convenient-memory-management",
    "href": "core.html#functions-for-convenient-memory-management",
    "title": "core",
    "section": "Functions for Convenient Memory Management",
    "text": "Functions for Convenient Memory Management\n\nsource\n\nclean_ipython_hist\n\n clean_ipython_hist ()\n\n\nsource\n\n\nclean_tb\n\n clean_tb ()\n\n\nsource\n\n\nclean_mem\n\n clean_mem ()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#weight-initialization-and-general-relu",
    "href": "core.html#weight-initialization-and-general-relu",
    "title": "core",
    "section": "Weight Initialization and General Relu",
    "text": "Weight Initialization and General Relu\n\nsource\n\ninit_weights\n\n init_weights (m, leaky=0.0)\n\n\nsource\n\n\nGeneralRelu\n\n GeneralRelu (leak=None, sub=None, maxv=None)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nact_genrelu = partial(GeneralRelu, leak=0.1, sub=0.4)",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#training-a-model",
    "href": "core.html#training-a-model",
    "title": "core",
    "section": "Training a Model",
    "text": "Training a Model\nObtain a single batch from dls to help with model design.\n\nidx = next(iter(dls.train))[0]\nidx, idx.shape\n\n(tensor([[16, 12, 13,  ...,  0,  0,  0],\n         [11,  1, 16,  ...,  0,  0,  0],\n         [11,  3,  6,  ...,  0,  0,  0],\n         ...,\n         [16, 19, 14,  ...,  0,  0,  0],\n         [ 9, 18, 10,  ...,  0,  0,  0],\n         [11, 17, 20,  ...,  0,  0,  0]]),\n torch.Size([32, 200]))\n\n\n\nTiny Resnet\nDesign a model architecture. Define functions to obtain 1D convolutional layers with an activation function and normalization and define a 1D residual block class.\n\nsource\n\n\nResBlock1d\n\n ResBlock1d (ni, nf, stride=1, ks=3, act=&lt;class\n             'torch.nn.modules.activation.ReLU'&gt;, norm=None)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nconv1d\n\n conv1d (ni, nf, ks=3, stride=2, act=&lt;class\n         'torch.nn.modules.activation.ReLU'&gt;, norm=None, bias=None)\n\nDefine a class that switches the rank order from BLC to BCL.\n\nsource\n\n\nReshape\n\n Reshape (*args, **kwargs)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\nPut the model together.\n\nlr = 1e-2\nepochs = 10\nn_embd = 16\ndls = get_dls(trnds, vldds, bs=32)\n\nmodel = nn.Sequential(nn.Embedding(vocab_size, n_embd, padding_idx=0), Reshape(),\n                      ResBlock1d(n_embd, 2, ks=15, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(2, 4, ks=13, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=11, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=9, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 8, ks=7, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 8, ks=5, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 16, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(16, 32, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      nn.Flatten(1, -1),\n                      nn.Linear(32, 1),\n                      nn.Flatten(0, -1),\n                      nn.Sigmoid())\nmodel(idx).shape\n\ntorch.Size([32])\n\n\n\niw = partial(init_weights, leaky=0.1)\nmodel = model.apply(iw)\nmetrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\nrec = RecorderCB(lr=_lr, beta1=_beta1, beta2=_beta2)\nastats = ActivationStats(fc.risinstance(GeneralRelu))\ncbs = [DeviceCB(), BatchSchedCB(), ProgressCB(plot=False), metrics, astats, rec]\n# cbs = [DeviceCB(), ProgressCB(plot=False), metrics, astats, rec] # for lr_find()\nlearn = TrainLearner(model, dls, F.binary_cross_entropy, lr=lr, cbs=cbs, opt_func=torch.optim.AdamW)\nprint(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\n# learn.lr_find(start_lr=1e-4, gamma=1.05, av_over=5, max_mult=5)\n\nParameters total: 10175\n\n\n\nlearn.fit(epochs)\n\n\n\n\n\n\n\n\nBinaryAccuracy\nBinaryMatthewsCorrCoef\nBinaryAUROC\nloss\nepoch\ntrain\n\n\n\n\n0.502\n-0.003\n0.499\n0.732\n0\ntrain\n\n\n0.507\n-0.022\n0.480\n0.701\n0\neval\n\n\n0.513\n0.003\n0.503\n0.698\n1\ntrain\n\n\n0.501\n-0.016\n0.494\n0.695\n1\neval\n\n\n0.528\n0.031\n0.518\n0.692\n2\ntrain\n\n\n0.473\n-0.014\n0.490\n0.695\n2\neval\n\n\n0.540\n0.058\n0.529\n0.689\n3\ntrain\n\n\n0.530\n0.026\n0.511\n0.689\n3\neval\n\n\n0.557\n0.100\n0.557\n0.683\n4\ntrain\n\n\n0.545\n0.060\n0.566\n0.681\n4\neval\n\n\n0.595\n0.185\n0.612\n0.667\n5\ntrain\n\n\n0.628\n0.247\n0.657\n0.639\n5\neval\n\n\n0.636\n0.271\n0.661\n0.641\n6\ntrain\n\n\n0.637\n0.266\n0.665\n0.633\n6\neval\n\n\n0.643\n0.291\n0.675\n0.631\n7\ntrain\n\n\n0.643\n0.287\n0.679\n0.626\n7\neval\n\n\n0.653\n0.313\n0.685\n0.623\n8\ntrain\n\n\n0.649\n0.301\n0.683\n0.619\n8\neval\n\n\n0.657\n0.322\n0.693\n0.617\n9\ntrain\n\n\n0.647\n0.291\n0.683\n0.621\n9\neval\n\n\n\n\n\nInspect the learning rate schedule applied during training.\n\nrec.plot()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#transformer-model-with-skip-connections-and-layernorm",
    "href": "core.html#transformer-model-with-skip-connections-and-layernorm",
    "title": "core",
    "section": "Transformer Model with Skip Connections and LayerNorm",
    "text": "Transformer Model with Skip Connections and LayerNorm\nThe transformer model below is adapted from the model built in Andrej Karpathy’s video Let’s build GPT: from scratch, in code, spelled out.\n\nsource\n\nHead\n\n Head (head_size)\n\nOne head of self-attention.\n\nsource\n\n\nFeedForward\n\n FeedForward (n_embed)\n\nA simple linear layer followed by a non-linearity.\n\nsource\n\n\nMultiHeadAttention\n\n MultiHeadAttention (num_heads, head_size)\n\nMultiple heads of self-attention in parallel.\n\nsource\n\n\nBlock\n\n Block (n_embd, n_head)\n\nTransformer block: communication (attention) followed by computation.\n\nsource\n\n\nTransformerModel\n\n TransformerModel (device)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nlr = 1e-3\nblock_size = 200\nepochs = 10\nn_embd = 16\nn_head = 8\nn_layer = 5\ndropout = 0.2\n\nmodel = TransformerModel(device='cpu')\nmodel(idx).shape\n\ntorch.Size([32])\n\n\n\ndls = get_dls(trnds, vldds, bs=32)\nmodel = TransformerModel(device=def_device)\niw = partial(init_weights, leaky=0.1)\nmodel = model.apply(iw)\nmetrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\nrec = RecorderCB(lr=_lr, beta1=_beta1, beta2=_beta2)\nastats = ActivationStats(fc.risinstance(GeneralRelu))\ncbs = [DeviceCB(), BatchSchedCB(), ProgressCB(plot=False), metrics, astats, rec]\nlearn = TrainLearner(model, dls, F.binary_cross_entropy_with_logits, lr=lr, cbs=cbs, opt_func=optim.AdamW)\nprint(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\n#learn.lr_find(start_lr=1e-5, gamma=1.1, av_over=3, max_mult=5)\n\nParameters total: 22929\n\n\n\nlearn.fit(epochs)\n\n\n\n\n\n\n\n\nBinaryAccuracy\nBinaryMatthewsCorrCoef\nBinaryAUROC\nloss\nepoch\ntrain\n\n\n\n\n0.520\n0.002\n0.504\n0.767\n0\ntrain\n\n\n0.534\n0.041\n0.534\n0.712\n0\neval\n\n\n0.535\n0.051\n0.537\n0.713\n1\ntrain\n\n\n0.539\n0.222\n0.626\n0.692\n1\neval\n\n\n0.602\n0.189\n0.627\n0.670\n2\ntrain\n\n\n0.659\n0.265\n0.683\n0.622\n2\neval\n\n\n0.632\n0.250\n0.668\n0.639\n3\ntrain\n\n\n0.654\n0.310\n0.697\n0.610\n3\neval\n\n\n0.639\n0.282\n0.687\n0.628\n4\ntrain\n\n\n0.660\n0.306\n0.712\n0.614\n4\neval\n\n\n0.651\n0.308\n0.704\n0.616\n5\ntrain\n\n\n0.658\n0.333\n0.721\n0.607\n5\neval\n\n\n0.656\n0.329\n0.719\n0.604\n6\ntrain\n\n\n0.650\n0.346\n0.722\n0.605\n6\neval\n\n\n0.667\n0.354\n0.737\n0.592\n7\ntrain\n\n\n0.662\n0.355\n0.726\n0.596\n7\neval\n\n\n0.674\n0.366\n0.743\n0.586\n8\ntrain\n\n\n0.672\n0.339\n0.726\n0.599\n8\neval\n\n\n0.672\n0.372\n0.748\n0.583\n9\ntrain\n\n\n0.662\n0.354\n0.725\n0.596\n9\neval\n\n\n\n\n\n\nrec.plot()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "atai",
    "section": "",
    "text": "Atomic AI is a flexible, minimalist deep neural network training framework based on Jeremy Howard’s miniai from the fast.ai 2022 course.",
    "crumbs": [
      "atai"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "atai",
    "section": "Install",
    "text": "Install\npip install atai",
    "crumbs": [
      "atai"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "atai",
    "section": "How to use",
    "text": "How to use\n\nfrom atai.core import *\n\nThe following example demonstrates how the Atomic AI training framework can be used to train a custom model that predicts protein solubility.\n\nImports\n\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.nn import init\nfrom torch import optim\n\nfrom torcheval.metrics import BinaryAccuracy, BinaryAUROC\nfrom torcheval.metrics.functional import binary_auroc, binary_accuracy\nfrom torchmetrics.classification import BinaryMatthewsCorrCoef\nfrom torchmetrics.functional.classification import binary_matthews_corrcoef\n\nimport fastcore.all as fc\nfrom functools import partial\n\n\n\nLoad Protein Solubility\nThis example uses the dataset from the DeepSol paper by Khurana et al. which was obtained at https://zenodo.org/records/1162886. It consists of amino acid sequences of peptides along with solubility labels that are 1 if the peptide is soluble and 0 if the peptide is insoluble.\n\ntrain_sqs = open('sol_data/train_src', 'r').read().splitlines()\ntrain_tgs = list(map(int, open('sol_data/train_tgt', 'r').read().splitlines()))\n\nvalid_sqs = open('sol_data/val_src', 'r').read().splitlines()\nvalid_tgs = list(map(int, open('sol_data/val_tgt', 'r').read().splitlines()))\n\ntrain_sqs[:2], train_tgs[:2]\n\n(['GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERVAAKVVLSKMTLGDLRNNPVVPYETDEVTRIIQDQVNDRIHDSIKNWTVEELREWILDHKTTDADIKRVARGLTSEIIAAVTKLMSNLDLIYGAKKIRVIAHANTTIGLPGTFSARLQPNHPTDDPDGILASLMEGLTYGIGDAVIGLNPVDDSTDSVVRLLNKFEEFRSKWDVPTQTCVLAHVKTQMEAMRRGAPTGLVFQSIAGSEKGNTAFGFDGATIEEARQLALQSGAATGPNVMYFETGQGSELSSDAHFGVDQVTMEARCYGFAKKFDPFLVNTVVGFIGPEYLYDSKQVIRAGLEDHFMGKLTGISMGCDVCYTNHMKADQNDVENLSVLLTAAGCNFIMGIPHGDDVMLNYQTTGYHETATLRELFGLKPIKEFDQWMEKMGFSENGKLTSRAGDASIFLK',\n  'MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEYSKTGDAWPCVLLRKKSFEDLHKLYYICLKEKNKLLGEQYFHLQNSTKMLQHGRLKKVKLTMKRILTVLSRRAIHDQCLRAKDMLKKQEEREFYEIQKFKLNEQLLCLKHKMNILKKYNSFSLEQISLTFSIKKIENKIQQIDIILNPLRKETMYLLIPHFKYQRKYSDLPGFISWKKQNIIALRNNMSKLHRLY'],\n [1, 0])\n\n\n\nlen(train_sqs), len(train_tgs), len(valid_sqs), len(valid_tgs)\n\n(62478, 62478, 6942, 6942)\n\n\n\n\nData Preparation\nCreate a sorted list of amino acid sequences aas including an empty string for padding and determine the size of the vocabulary.\n\naas = sorted(list(set(\"\".join(train_sqs))) + [\"\"])\nvocab_size = len(aas)\naas, vocab_size\n\n(['',\n  'A',\n  'C',\n  'D',\n  'E',\n  'F',\n  'G',\n  'H',\n  'I',\n  'K',\n  'L',\n  'M',\n  'N',\n  'P',\n  'Q',\n  'R',\n  'S',\n  'T',\n  'V',\n  'W',\n  'Y'],\n 21)\n\n\nCreate dictionaries that translate between string and integer representations of amino acids and define the corresponding encode and decode functions.\n\nstr2int = {aa:i for i, aa in enumerate(aas)}\nint2str = {i:aa for i, aa in enumerate(aas)}\nencode = lambda s: [str2int[aa] for aa in s]\ndecode = lambda l: ''.join([int2str[i] for i in l])\n\nprint(encode(\"AYWCCCGGGHH\"))\nprint(decode(encode(\"AYWCCCGGGHH\")))\n\n[1, 20, 19, 2, 2, 2, 6, 6, 6, 7, 7]\nAYWCCCGGGHH\n\n\nFigure out what the range of lengths of amino acid sequences in the dataset is.\n\ntrain_lens = list(map(len, train_sqs))\nmin(train_lens), max(train_lens)\n\n(19, 1691)\n\n\nCreate a function that drops all sequences above a chosen threshold and also returns a list of indices of the sequences that meet the threshold that can be used to obtain the correct labels.\n\ndef drop_long_sqs(sqs, threshold=1200):\n    new_sqs = []\n    idx = []\n    for i, sq in enumerate(sqs):\n        if len(sq) &lt;= threshold:\n            new_sqs.append(sq)\n            idx.append(i)\n    return new_sqs, idx\n\nDrop all sequences above your chosen threshold.\n\ntrnsqs, trnidx = drop_long_sqs(train_sqs, threshold=200)\nvldsqs, vldidx = drop_long_sqs(valid_sqs, threshold=200)\n\n\nlen(trnidx), len(vldidx)\n\n(18066, 1971)\n\n\n\nmax(map(len, trnsqs))\n\n200\n\n\nCreate a function for zero padding all sequences.\n\ndef zero_pad(sq, length=1200):\n    new_sq = sq.copy()\n    if len(new_sq) &lt; length:\n        new_sq.extend([0] * (length-len(new_sq)))\n    return new_sq\n\nNow encode and zero pad all sequences and make sure that it worked out correctly.\n\ntrn = list(map(encode, trnsqs))\nvld = list(map(encode, vldsqs))\nprint(f\"Length of the first two sequences before zero padding: {len(trn[0])}, {len(trn[1])}\")\ntrn = list(map(partial(zero_pad, length=200), trn))\nvld = list(map(partial(zero_pad, length=200), vld))\nprint(f\"Length of the first two sequences after zero padding:  {len(trn[0])}, {len(trn[1])}\");\n\nLength of the first two sequences before zero padding: 116, 135\nLength of the first two sequences after zero padding:  200, 200\n\n\nConvert the data to torch.tensors unsing dtype=torch.int64 and check for correctness.\n\ntrntns = torch.tensor(trn, dtype=torch.int64)\nvldtns = torch.tensor(vld, dtype=torch.int64)\ntrntns.shape, trntns[0]\n\n(torch.Size([18066, 200]),\n tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]))\n\n\n\ntrntns.shape, vldtns.shape\n\n(torch.Size([18066, 200]), torch.Size([1971, 200]))\n\n\nObtain the correct labels using the lists of indices obtained from the drop_long_sqs function and convert the lists of labels to tensors in torch.float32 format.\n\ntrnlbs = torch.tensor(train_tgs, dtype=torch.float32)[trnidx]\nvldlbs = torch.tensor(valid_tgs, dtype=torch.float32)[vldidx]\ntrnlbs.shape, vldlbs.shape\n\n(torch.Size([18066]), torch.Size([1971]))\n\n\nCalculate the ratios of soluble peptides in the train and valid data.\n\ntrnlbs.sum().item()/trnlbs.shape[0], vldlbs.sum().item()/vldlbs.shape[0]\n\n(0.4722129967895494, 0.4657534246575342)\n\n\nThese ratios tell us that there are slightly less than half soluble proteins in the training an validation data, and slightly more than half in the test set.\n\n\nDataset and DataLoaders\nTurn train and valid data into datasets using the Dataset class.\n\ntrnds = Dataset(trntns, trnlbs)\nvldds = Dataset(vldtns, vldlbs)\ntrnds[0]\n\n(tensor([11,  9,  1, 10,  2, 10, 10, 10, 10, 13, 18, 10,  6, 10, 10, 18, 16, 16,  9, 17, 10,  2, 16, 11,  4,  4,  1,  8, 12,  4, 15,  8, 14,\n          4, 18,  1,  6, 16, 10,  8,  5, 15,  1,  8, 16, 16,  8,  6, 10,  4,  2, 14, 16, 18, 17, 16, 15,  6,  3, 10,  1, 17,  2, 13, 15,  6,\n          5,  1, 18, 17,  6,  2, 17,  2,  6, 16,  1,  2,  6, 16, 19,  3, 18, 15,  1,  4, 17, 17,  2,  7,  2, 14,  2,  1,  6, 11,  3, 19, 17,\n          6,  1, 15,  2,  2, 15, 18, 14, 13, 10,  4,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]),\n tensor(0.))\n\n\nUse the get_dls function to obtain the dataloaders from the train and valid datasets.\n\ndls = get_dls(trnds, vldds, bs=32)\nnext(iter(dls.train))[0][:2], next(iter(dls.train))[1][:2]\n\n(tensor([[11,  1,  7,  7,  7,  7,  7,  7, 11, 11, 13, 15, 16,  4, 12, 14,  9,  4,  4,  4,  4, 19,  4, 10,  7, 13, 10,  5, 10, 16,  9,  8, 13,\n          12,  9,  9,  3,  8,  3,  9, 12, 13,  1, 10, 16,  1, 10,  8, 17, 10,  8, 12,  4,  4,  4,  4,  9,  4, 18,  5, 16, 20,  4, 13, 15, 15,\n           9, 12, 10,  9,  9,  9,  8, 17,  4,  9,  6, 14,  8,  8, 20,  9,  9,  3, 15, 15, 12, 10, 20,  4, 13, 20, 14, 14, 12,  9, 12,  3,  9,\n           8, 12, 20,  5,  4,  9,  9, 12,  5,  6,  6, 12,  1,  3,  8, 16,  9,  4,  4,  4, 18, 10,  3, 18,  4, 11,  3,  4,  4,  6, 17, 17, 18,\n          17, 17,  1,  4, 14,  6,  6,  3,  7, 16, 16, 14, 12, 18, 16, 12, 12, 14,  4,  1, 17,  3, 14, 17, 16,  8,  6,  4, 18, 10, 18,  2, 10,\n          16, 11, 11, 12, 10,  9, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0],\n         [11, 10,  1, 11, 18, 12,  9, 18, 10,  3, 19,  8, 15, 16, 10,  5, 19,  9,  4,  4, 11,  4, 10, 17, 10, 18,  6, 10, 14, 12, 16,  6,  9,\n          17, 17,  5, 18, 12, 18,  8,  1, 16,  6, 14,  5, 17,  4,  3, 11,  8, 13, 17, 18,  6,  5, 12, 11, 15,  9,  8, 17,  9,  6, 12, 18, 17,\n           8,  9, 10, 19,  3,  8,  6,  6, 14, 13, 15,  5, 15, 16, 11, 19,  4, 15, 20,  2, 15,  6, 18, 12,  1,  8, 18,  5, 11, 18,  3,  1,  1,\n           3,  4,  4,  9, 10,  4,  1, 16, 15, 12,  4, 10, 11, 14, 10, 10,  3,  9, 13, 14, 10,  3,  1,  8, 13, 18, 10, 18, 10,  6, 12,  9,  9,\n           3, 10, 13,  6,  1, 10,  3,  4, 15, 14, 10,  8,  4, 15, 11, 12, 10, 16, 16,  8, 14, 12, 15,  4,  8,  2,  2, 20, 16,  8, 16,  2,  9,\n           4,  9,  4, 12,  8,  3,  8, 17, 10, 14, 19, 10,  8,  3,  7, 16,  9,  1, 14, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0]]),\n tensor([1., 0.]))\n\n\n\n\nDesign Your Model\nLet’s create a tiny model (~10k parameters) that uses a sequence of 1-dimensional convolutional layers with skip connections, kaiming he initialization, leaky relus, batchnorm, and dropout.\nFirst, obtain a single batch from dls to help design the model.\n\nidx = next(iter(dls.train))[0] ## a single batch\nidx, idx.shape\n\n(tensor([[11,  9, 17,  ...,  0,  0,  0],\n         [16, 12,  1,  ...,  0,  0,  0],\n         [16,  1, 14,  ...,  0,  0,  0],\n         ...,\n         [11,  1,  7,  ...,  0,  0,  0],\n         [11,  3, 13,  ...,  0,  0,  0],\n         [16, 17, 12,  ...,  0,  0,  0]]),\n torch.Size([32, 200]))\n\n\n\nCustom Modules\n\ndef conv1d(ni, nf, ks=3, stride=2, act=nn.ReLU, norm=None, bias=None):\n    if bias is None: bias = not isinstance(norm, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d))\n    layers = [nn.Conv1d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias)]\n    if norm: layers.append(norm(nf))\n    if act: layers.append(act())\n    return nn.Sequential(*layers)\n\ndef _conv1d_block(ni, nf, stride, act=nn.ReLU, norm=None, ks=3):\n    return nn.Sequential(conv1d(ni, nf, stride=1, act=act, norm=norm, ks=ks),\n                         conv1d(nf, nf, stride=stride, act=None, norm=norm, ks=ks))\n\nclass ResBlock1d(nn.Module):\n    def __init__(self, ni, nf, stride=1, ks=3, act=nn.ReLU, norm=None):\n        super().__init__()\n        self.convs = _conv1d_block(ni, nf, stride=stride, ks=ks, act=act, norm=norm)\n        self.idconv = fc.noop if ni==nf else conv1d(ni, nf, stride=1, ks=1, act=None)\n        self.pool = fc.noop if stride==1 else nn.AvgPool1d(stride, ceil_mode=True)\n        self.act = act()\n\n    def forward(self, x): return self.act(self.convs(x) + self.pool(self.idconv(x)))\n\nThe following module switches the rank order from BLC to BCL.\n\nclass Reshape(nn.Module):\n    def forward(self, x): \n        B, L, C = x.shape\n        return x.view(B, C, L)\n\n\n\nModel Architecture\n\nlr = 1e-2\nepochs = 30\nn_embd = 16\ndls = get_dls(trnds, vldds, bs=32)\nact_genrelu = partial(GeneralRelu, leak=0.1, sub=0.4)\n\nmodel = nn.Sequential(nn.Embedding(vocab_size, n_embd, padding_idx=0), Reshape(),\n                      ResBlock1d(n_embd, 2, ks=15, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(2, 4, ks=13, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=11, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=9, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 8, ks=7, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 8, ks=5, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 16, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(16, 32, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      nn.Flatten(1, -1),\n                      nn.Linear(32, 1),\n                      nn.Flatten(0, -1),\n                      nn.Sigmoid())\nmodel(idx).shape\n\ntorch.Size([32])\n\n\n\niw = partial(init_weights, leaky=0.1)\nmodel = model.apply(iw)\nmetrics = MetricsCB(BinaryAccuracy(), BinaryMatthewsCorrCoef(), BinaryAUROC())\nastats = ActivationStats(fc.risinstance(GeneralRelu))\ncbs = [DeviceCB(), ProgressCB(plot=False), metrics, astats]\nlearn = TrainLearner(model, dls, F.binary_cross_entropy, lr=lr, cbs=cbs, opt_func=torch.optim.AdamW)\nprint(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\nlearn.lr_find(start_lr=1e-4, gamma=1.05, av_over=3, max_mult=5)\n\nParameters total: 10175\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/10 00:00&lt;?]\n    \n    \n\n\n    \n      \n      88.85% [502/565 00:32&lt;00:04 0.919]\n    \n    \n\n\n\n\n\n\n\n\n\nThis is a pretty noisy training set, so the learning rate finder does not work very well. Yet it is possible to get a somewhat informative result using the av_over keyword argument that tells lr_find to average over the specified number of batches for each learning rate tested. It also helps to dial the gamma value down from its default value of 1.3.\n\n\n\nTraining\n\nlearn.fit(epochs)\n\n\n\n\n\n\n\n\nBinaryAccuracy\nBinaryMatthewsCorrCoef\nBinaryAUROC\nloss\nepoch\ntrain\n\n\n\n\n0.510\n0.008\n0.507\n0.722\n0\ntrain\n\n\n0.527\n-0.033\n0.494\n0.691\n0\neval\n\n\n0.515\n0.004\n0.506\n0.695\n1\ntrain\n\n\n0.534\n0.003\n0.520\n0.691\n1\neval\n\n\n0.537\n0.054\n0.526\n0.692\n2\ntrain\n\n\n0.530\n0.058\n0.550\n0.693\n2\neval\n\n\n0.553\n0.090\n0.551\n0.688\n3\ntrain\n\n\n0.562\n0.108\n0.575\n0.684\n3\neval\n\n\n0.589\n0.170\n0.607\n0.671\n4\ntrain\n\n\n0.619\n0.234\n0.663\n0.647\n4\neval\n\n\n0.622\n0.247\n0.630\n0.653\n5\ntrain\n\n\n0.643\n0.302\n0.676\n0.637\n5\neval\n\n\n0.627\n0.260\n0.642\n0.650\n6\ntrain\n\n\n0.649\n0.313\n0.675\n0.628\n6\neval\n\n\n0.633\n0.272\n0.647\n0.644\n7\ntrain\n\n\n0.650\n0.309\n0.648\n0.637\n7\neval\n\n\n0.634\n0.276\n0.652\n0.640\n8\ntrain\n\n\n0.650\n0.314\n0.683\n0.620\n8\neval\n\n\n0.637\n0.284\n0.646\n0.641\n9\ntrain\n\n\n0.651\n0.320\n0.685\n0.617\n9\neval\n\n\n0.639\n0.287\n0.661\n0.636\n10\ntrain\n\n\n0.645\n0.308\n0.671\n0.647\n10\neval\n\n\n0.638\n0.281\n0.663\n0.636\n11\ntrain\n\n\n0.646\n0.298\n0.690\n0.620\n11\neval\n\n\n0.641\n0.286\n0.670\n0.632\n12\ntrain\n\n\n0.648\n0.296\n0.685\n0.619\n12\neval\n\n\n0.641\n0.290\n0.668\n0.632\n13\ntrain\n\n\n0.662\n0.323\n0.691\n0.618\n13\neval\n\n\n0.643\n0.290\n0.675\n0.630\n14\ntrain\n\n\n0.641\n0.286\n0.677\n0.627\n14\neval\n\n\n0.643\n0.289\n0.676\n0.630\n15\ntrain\n\n\n0.659\n0.311\n0.699\n0.616\n15\neval\n\n\n0.644\n0.291\n0.677\n0.629\n16\ntrain\n\n\n0.652\n0.314\n0.690\n0.613\n16\neval\n\n\n0.646\n0.296\n0.675\n0.626\n17\ntrain\n\n\n0.645\n0.282\n0.694\n0.622\n17\neval\n\n\n0.642\n0.288\n0.678\n0.626\n18\ntrain\n\n\n0.648\n0.332\n0.677\n0.639\n18\neval\n\n\n0.645\n0.292\n0.685\n0.625\n19\ntrain\n\n\n0.634\n0.260\n0.698\n0.615\n19\neval\n\n\n0.649\n0.302\n0.689\n0.621\n20\ntrain\n\n\n0.651\n0.344\n0.710\n0.617\n20\neval\n\n\n0.648\n0.299\n0.685\n0.624\n21\ntrain\n\n\n0.660\n0.315\n0.700\n0.614\n21\neval\n\n\n0.648\n0.297\n0.691\n0.620\n22\ntrain\n\n\n0.563\n0.168\n0.679\n0.672\n22\neval\n\n\n0.651\n0.303\n0.690\n0.620\n23\ntrain\n\n\n0.654\n0.330\n0.710\n0.611\n23\neval\n\n\n0.650\n0.304\n0.691\n0.620\n24\ntrain\n\n\n0.668\n0.344\n0.711\n0.599\n24\neval\n\n\n0.654\n0.311\n0.692\n0.617\n25\ntrain\n\n\n0.649\n0.294\n0.698\n0.620\n25\neval\n\n\n0.650\n0.301\n0.690\n0.617\n26\ntrain\n\n\n0.642\n0.320\n0.697\n0.611\n26\neval\n\n\n0.650\n0.303\n0.688\n0.620\n27\ntrain\n\n\n0.663\n0.334\n0.708\n0.625\n27\neval\n\n\n0.652\n0.308\n0.694\n0.616\n28\ntrain\n\n\n0.672\n0.356\n0.711\n0.597\n28\neval\n\n\n0.651\n0.304\n0.695\n0.617\n29\ntrain\n\n\n0.659\n0.322\n0.702\n0.603\n29\neval\n\n\n\n\n\n\n\nInspect Activations\n\ndls = get_dls(trnds, vldds, bs=256)\n\nmodel = nn.Sequential(nn.Embedding(vocab_size, n_embd, padding_idx=0), Reshape(),\n                      ResBlock1d(n_embd, 2, ks=15, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(2, 4, ks=13, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=11, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 4, ks=9, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(4, 8, ks=7, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 8, ks=5, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(8, 16, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      ResBlock1d(16, 32, ks=3, stride=2, norm=nn.BatchNorm1d, act=act_genrelu), nn.Dropout(0.1),\n                      nn.Flatten(1, -1),\n                      nn.Linear(32, 1),\n                      nn.Flatten(0, -1),\n                      nn.Sigmoid())\n\nmodel = model.apply(iw)\nastats = ActivationStats(fc.risinstance(GeneralRelu))\ncbs = [DeviceCB(), astats]\nlearn = TrainLearner(model, dls, F.binary_cross_entropy, lr=lr, cbs=cbs, opt_func=torch.optim.AdamW)\nprint(f\"Parameters total: {sum(p.nelement() for p in model.parameters())}\")\nlearn.fit(1)\n\nParameters total: 10175\n\n\n\nastats.color_dim()\n\n\n\n\n\n\n\n\n\nastats.plot_stats()\n\n\n\n\n\n\n\n\n\nastats.dead_chart()",
    "crumbs": [
      "atai"
    ]
  }
]